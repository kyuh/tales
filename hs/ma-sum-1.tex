%!TEX root = tales-main.tex

% (numbers, functions,)
\chapter{The Small, Large, and Infinite}

\section{Introduction}



\section{Numbers}


\section{Communication}

\subsection{Variables}

In the language of math and science, we often use \textbf{variables} to generally indicate the quantities we're talking about. For example, we could say:

\begin{itemize}
\item "Let $v$ be the velocity of this object." % TODO: Finish this up
\end{itemize}

We could also say something like:

\begin{itemize}
\item "Let $a$ and $b$ be the length of the two sides indicated in the right triangle below."
\end{itemize}

% TODO: Insert such a figure


\subsection{Statements}

Often times, these variables will be part of various statements we make. For example, 
\begin{itemize}
\item "For objects of this type, there seems to be a drag force, proportional to $v^2$." 
\end{itemize}

This would be a \textbf{hypothesis}, usually then supported by experiments. 

Alternatively, we could have a statement like:

\begin{itemize}
\item "Let $a$ and $b$ be the length of the two sides indicated in the right triangle below. Then the triangle's area is given by $\frac{1}{2}ab$."
\end{itemize}

This would be more of a mathematical statement, proven true based the properties of area.

\subsubsection{(Experiment vs mathematical statements)}
% TODO

In experimental science, statements often take the form of hypotheses. Then, experiments are conducted in order to provide evidence for or against them.

In mathematics, statements generally have a "truth value" to them.\footnote{TODO: Talk about axioms and stuff?} For example:

\begin{itemize}
\item The statement "3 is greater than 2" (i.e. $3 > 2$) is true. 
\item The statement "6 is a prime number" is false. 
\end{itemize}


\subsection{Operations and other symbols}

We often use other notation in order to get our point across more clearly and/or concisely. 

For example, suppose you wanted to talk about the sum:
\begin{align*}
1 + 2 + 3 + 4 + ... + n
\end{align*}

That sometimes becomes annoying to write. Often, we use the $\sum$ symbol instead (it's a capital Greek letter). It usually indicates the specific range of values we're summing over. % -- for example, $\sum_{i=1}^n (\text{\textit{expression involving i}})$

As an example, we could write the above sum as:
\begin{align*}
\sum_{i=1}^n i
\end{align*}

If we wanted to write the sum
\begin{align*}
6 + 8 + 10 + 12 + 14 + 16 + 18 + 20 + 22 + 24
\end{align*}

we could instead write:
\begin{align*}
\sum_{i=3}^{12} 2i
\end{align*}

There are actually a lot of ways we could have written it, for example:
we could instead write:
\begin{align*}
\sum_{i=5}^{14} 2(i-2)
\end{align*}


We'll encounter a lot more situations like this throughout the rest of the book, where introducing convenient notation will make expressing our ideas easier.

\begin{exercise}
\label{sigma-notation-prac-1}
The sum $12 + 15 + 18 + 21 + 24 + ... + 36 + 39 + 42$ is annoying to write. Can you write it using our "sigma notation" above?
\end{exercise}

\begin{exercise}
\label{sigma-notation-prac-2}
What about the sum $8 + 11 + 14 + 17 + 20 + 23 + 26$?
\end{exercise}
% TODO: Give alternate solutions as well.


%The position of an object, the amount of fluid in a bucket, the concentration of something in something else (say, of oxygen in the air), the force generated by a rocket's engines -- these are all things describable with some combination of numbers and "units" (which tell us "numbers of what"). 

% TODO: Clarify what a reference point is.

%Some fitting examples of such quantities, respectively, could be "5.266 feet to the right of that telephone pole"\footnote{This quantity also has a "reference point". The quantity "5.266 feet" alone wouldn't very useful in describing where our object is.}, "15.2 grams per liter (or 15.2 g/L)", and 7,500,000 pounds.\footnote{Saturn V first stage thrust, \url{https://en.wikipedia.org/wiki/Saturn_V}}

% TODO: Possibly clarify that the telephone pole is a reference point. 
% TODO: That footnote looks an awful lot like a square.  


%Moreover, unlike some other measurements -- such as the number of balls in an urn, or the number of times the word "the" appears in this book -- we can describe our previous quantities with a much greater set of numbers than the "counting numbers" $(1, 2, 3, ...)$. We can't really have 1.6 balls in an urn (even if a ball were cut up, it's not really a "ball" anymore), but it makes sense to have 1.6 liters of fluid in a bucket. We could also have 1.7 liters in that bucket, or pretty much any quantity in between 1.6 and 1.7 liters (1.6333, $\frac{1 + \sqrt{5}}{2}$\footnote{This quantity is called the "golden ratio", and it appears in a lot of interesting places. Look it up!}, etc.) - any such value would make sense here. \footnote{Some of you may be thinking about the fact that fluid is just a bunch of atoms and molecules, and that those aren't really indivisible. But our "infinitely divisible fluid" is a nice approximation for now.}

% TODO: Again, footnotes are numbers. This is annoying and confusing.


\section{Counting numbers}

We'll start our first real mathematical tale by looking at numbers themselves. 

Here, we'll focus on the \textbf{counting numbers}: 1, 2, 3, 4, ... and so on. Practically, they're used to describe the quantity of things that can't really be divided into parts (for example, you can have 1.42 liters of water, but you can't have 1.42 balls in a jar). 

\subsection{Definition}

How can we \emph{define} what we mean by counting numbers? ("Numbers for counting balls" doesn't quite cut it.)

We know that the numbers should be 1, 2, 3, 4, ... and so on. How do we know what the "and so on" should be?

One way is to consider the "order" of the numbers. We know that, in some sense, 7 comes after 6, which comes after 5, which comes after 4, ... 

More precisely, if we have some number $k$, we know that $k+1$ comes after it. 

There's also a number that doesn't "come after" anyone else: The number 1.

Using these facts, let's define the counting numbers as the set (or collection) of numbers which has the following properties:

\begin{itemize}
\item 1 is in the collection.
\item If $k$ is in the collection, then $k+1$ is as well. 
\end{itemize}

\begin{exercise}
The numbers 2, 4, 6, 8, ... are often called the \textbf{even numbers}. Can you define these similarly?
\end{exercise}
% TODO: Present solutions in two ways! the 2*n method, and the one similar to above.


\subsection{The Principle of Mathematical Induction}

Consider the following sums:
\begin{align*}
1 &= 1 \\
1 + 2 &= 3 \\
1 + 2 + 3 &= 6 \\
1 + 2 + 3 + 4 &= 10 \\
1 + 2 + 3 + 4 + 5 &= 15 \\
1 + 2 + 3 + 4 + 5 + 6 &= 21 \\
1 + 2 + 3 + 4 + 5 + 6 + 7 &= 28 \\
\end{align*}
% TODO: Needs better formatting

Or, to use our "sigma notation":
\begin{align*}
\sum_{i=1}^1 i &= 1 \\
\sum_{i=1}^2 i &= 3 \\
\sum_{i=1}^3 i &= 6 \\
\sum_{i=1}^4 i &= 10 \\
\sum_{i=1}^5 i &= 15 \\
\sum_{i=1}^6 i &= 21 \\
\sum_{i=1}^7 i &= 28 \\
\end{align*}

Do you see the pattern? Better yet, can you see a "formula" for getting the sum from 1 to $n$ (in other words, $\sum_{i=1}^n i$) for any "counting number" $n$?

\newpage

I claim that:

\begin{equation}
\label{sum-i}
\sum_{i=1}^n i = \frac{n(n+1)}{2}
\end{equation}

I'd like to prove that this equation is true when $n$ is any counting number. How can I do it? 

Remember how we defined the counting numbers? Well, let's say I instead consider the "collection of numbers for which Equation \ref{sum-i} is true". 

Then suppose I show that Equation \ref{sum-i} is true when $n = 1$ -- in other words, 1 is in this "collection of numbers". Then let's show that, as long as we assume Equation \ref{sum-i} is true when $n = k$ for some value $k$, we can then prove that Equation \ref{sum-i} is true when $n = k + 1$. In other words, if $k$ is in our collection, then $k+1$ is as well.

Do you see where we're going with this? If we show the above true things, then we've shown that the "collection of numbers for which Equation \ref{sum-i} is true" is in fact the counting numbers. In other words, Equation \ref{sum-i} is then true whenever $n$ is a counting number!

\begin{exercise}
Before we go any further, try out Equation \ref{sum-i} for yourself. Plug in 1 through 7 for $n$, and see if you get the answers you expect. 
\end{exercise}

\subsubsection{Proof}

Let's do exactly what we just said.

First, let's see whether our formula is true when $n=1$. On the left side of Equation \ref{sum-i}, we see that 

\begin{align*}
\sum_{i=1}^{1} i = 1
\end{align*}

And on the right side, we see that:
\begin{align*}
\frac{1(1+1)}{2} = \frac{1 \cdot 2}{2} = \frac{2}{2} = 1
\end{align*}

So the statement holds at $n = 1$. Great!

Now for the second part. (We often call this part the \textbf{inductive step}.) Suppose the statement were true at $n = k$. In other words, suppose we knew that, at some value $k$:

\begin{equation*}
\sum_{i=1}^k i = \frac{k(k+1)}{2}
\end{equation*}

Let's try to now prove that the statement is true at $n = k + 1$. In other words, we wish to prove that:
\begin{align*}
\sum_{i=1}^{k+1} i = \frac{(k+1)((k+1)+1)}{2}
\end{align*}

Or, simplifying a bit, we want to prove:
\begin{align*}
\sum_{i=1}^{k+1} i = \frac{(k+1)(k+2)}{2}
\end{align*}

Let's try it! Starting from the left side, we see that:
\begin{align*}
\sum_{i=1}^{k+1} i &= \sum_{i=1}^{k} i + (k+1) && \text{(I'm splitting a term from our sigma-expression. See why it works?)} \\
&= \frac{k(k+1)}{2} + (k+1) && \text{(We're assuming the statement is true at $n=k$, so substitute it in.)} \\
&= \frac{k(k+1)}{2} + \frac{2(k+1)}{2} \\
&= \frac{k(k+1) + 2(k+1)}{2} \\
&= \frac{(k+1)(k+2)}{2} && \text{(Factor out k+1)}\\
\end{align*}

We've done it -- we've shown that, if we assume Equation \ref{sum-i} is true when $n=k$, we've shown that, as a consequence, it must be true for $n = k+1$. 

% TODO: Need some philosophical pondering here / more on why this is exciting
% Also note that this is the "principle of mathematical induction"

\begin{exercise}
\label{sum-i2}
I claim that there is also a nice formula for the sum of $i^2$ from 1 through $n$. Namely:

\begin{equation}
\label{eq:sum-i2}
\sum_{i=1}^{n} i^2 = \frac{n(n+1)(2n+1)}{6}
\end{equation}

Prove that this statement is true whenever $n$ is a counting number, using induction.
\end{exercise}


\section{Counting things}

%This leads us into our second tale of the chapter.

% OLD? TODO: Explain perms/combs
% OLD? Briefly incorporate "sequence" vocal (don't need to formally define it yet)


% maybe should be an "official" subsection?
\subsection{Arranging things}


How many ways can I arrange the letters $a$, $b$, $c$, and $d$?

% Possible TODO: brief lead-in here? (even if it's only half a sentence)
Let's write them out:

\begin{gather*}
(a, b, c, d) \\
(a, b, d, c) \\
(a, c, b, d) \\
(a, c, d, b) \\
(a, d, b, c) \\
(a, d, c, b) \\
(b, a, c, d) \\
(b, a, d, c) \\
(b, c, a, d) \\
(b, c, d, a) \\
(b, d, a, c) \\
(b, d, c, a) \\
(c, a, b, d) \\
(c, a, d, b) \\
(c, b, a, d) \\
(c, b, d, a) \\
(c, d, a, b) \\
(c, d, b, a) \\
(d, a, b, c) \\
(d, a, c, b) \\
(d, b, a, c) \\
(d, b, c, a) \\
(d, c, a, b) \\
(d, c, b, a) \\
\end{gather*}

In case you feel like counting, there are 24 of them.

But writing out all our possibilities is slightly annoying, even with only four letters. (Imagine using more!) We might even have missed some! How could we have figured out how many we have otherwise, perhaps with more confidence? % ("more rigorously") 

Hopefully the order in which we wrote the above permutations is a bit revealing. Delving a little deeper, we can divide our arrangements into 4 possibilities:

\begin{enumerate}
\item Those that start with $a$
\item Those that start with $b$
\item Those that start with $c$
\item Those that start with $d$
\end{enumerate}

Let's look at the ones that start with the letter $a$. In each such arrangement, the only letters that can be used for the last three spaces are $b$, $c$, and $d$. 

Similar things happen in the other cases. If we take one of the letters and use it as our first, the last three characters must be taken from the three characters we haven't used yet. (For example, if we use $b$ as our first character, then our last three characters must be an ordering using the letters $a$, $c$, and $d$ in some order.) % Explain better?

This leads us to a really important observation. Our original problem, in essence, was to determine the "number of possible arrangements of 4 distinct things". We can divide this problem into 4 separate scenarios (the 4 cases), each of which has a smaller, but very similar problem -- the "number of possible arrangements of 3 distinct things".

% TODO: Explain that we have 4 times the number of 3 things. (And more explanation on this point in general.) 

%\footnote{It doesn't really matter that they are the letters $a$, $b$, $c$, and $d$, as opposed to the letters $x$, $z$, $w$, and $q$, or the numbers 1, 2, 3, and 4, or balls of colors red, yellow, green, and blue.} \footnote{What \emph{does} matter is \emph{distinctness} -- if I were to try to find the number ... TODO: Discuss distinctness, and getting to non-distinctness later?} 

Let's come up with some better notation. Let $p_n$ denote the "number of possible arrangements of $n$ things". Our observation is that:

\begin{equation*}
p_4 = 4 \cdot p_3
\end{equation*}

% TODO: need some sort of break here? (maybe just space)

Let's try reducing part of our problem even more. Remember all those arrangements that started with the letter $a$?

\begin{gather*}
(a, b, c, d) \\
(a, b, d, c) \\
(a, c, b, d) \\
(a, c, d, b) \\
(a, d, b, c) \\
(a, d, c, b) \\
\end{gather*}

As we mentioned, they all consist of the letter $a$, followed by each possible ordering using the letters $b$, $c$, and $d$. We list those here:

\begin{gather*}
(b, c, d) \\
(b, d, c) \\
(c, b, d) \\
(c, d, b) \\
(d, b, c) \\
(d, c, b) \\
\end{gather*}

We can now do something very similar to before. Now, there are 3 cases (starting with $b$, $c$, or $d$ -- and in each case, using the remaining 2 letters to form orderings of length 2). Hopefully you agree with the observation that:

\begin{equation*}
p_3 = 3 \cdot p_2
\end{equation*}

% TODO: space/break?

In fact, hopefully you agree with a more general statement: For counting numbers $n$,

\begin{equation}
p_n = n \cdot p_{n-1}
\end{equation}

In other words, the number of ways to arrange $n$ distinct letters (or other things) is given by $n$ times the same problem, but for $(n-1)$. 

% TODO: (Maybe here, maybe elsewhere) Discuss how this type of thing is a "recursive relationship" (and relation to induction)

There's a little bit of nuance to consider here. What if $n$ is 1? Then $(n-1)$ is 0, and we haven't considered 0 a counting number. In other words, we need to stop subtracting 1 somewhere.

Similar to our induction, let's consider some sort of "base case". What is $p_1$? If we only have 1 thing, there's really only 1 way to arrange it. Hence, to complement our relation above, we have the base case:

\begin{equation}
p_1 = 1
\end{equation}


% TODO: Maybe need to revise the original induction section to start at 0, and for any of those inductive relations that involve starting at some number, discuss the process as being equivalent to all integers above (that starting number). 

% TODO: Explain product notation, and then lead to factorial when starting idx is 1. 

% TODO: Footnote or something noting that our "arrangements" are usually called permutations elsewhere.

% TODO: Need to restate recursion and base case together, and give (ideally combined) equation number

\begin{exercise}
In our four-letter example, it didn't really matter that we used the letters $a$, $b$, $c$, and $d$, as opposed to the letters $x$, $z$, $w$, and $q$, or the numbers 1, 2, 3, and 4, or balls of colors red, yellow, green, and blue. The number of ways to arrange each of these groups of 4 things is still 24.

Each of these example groups has four \textbf{distinct} objects. As a contrasting example, let's say we now have the four characters $b$, $b$, $c$, and $d$ to make arrangements with. ($b$ now occurs twice, so even though we have four letters, two of them are the same.)

Try to write down all the ways to arrange this group of four letters. Can you still get 24 arrangements?

%What does matter is \textbf{distinctness} -- if we were to try to find the number of ways to arrange the letters $b$, $b$, $c$, and $d$ (i.e. $b$ occurring twice), we may get different results.

(We will cover non-distinct arrangements later in the chapter.)
\end{exercise}

\subsubsection{(Handling 0)}

% TODO: Explain how the definition makes sense for n = 0. 
% (May not need to if we revise the induction section, etc to start at 0)


\subsection{(Arrangements of $k$ from $n$)}
% TODO: (Maybe these should all just be unnamed sections, or even just space?)

Let's now consider a slightly different problem. Suppose we still have the letters $a$, $b$, $c$, and $d$ -- but this time, we can only use them to form arrangements that are two letters long.

We could write out all of our possibilities. Here they are:

\begin{gather*}
(a, b) \\
(a, c) \\
(a, d) \\
(b, a) \\
(b, c) \\
(b, d) \\
(c, a) \\
(c, b) \\
(c, d) \\
(d, a) \\
(d, b) \\
(d, c) \\
\end{gather*}

These are slightly easier to list. However, let's do a similar process.

Let $q_{n,k}$ denote the number of ways to make an ordering of length $k$, from $n$ distinct letters (or other things), and let's consider $q_{4,2}$. As before, we have four "groups" of arrangements based on our starting character (again, the 4 cases being those that start with $a$, $b$, $c$, or $d$). Within each of these 4 cases, we then have the problem of selecting an "arrangement of length 1" (in other words, just a character) from the remaining three available characters. Therefore, our observation is that:

\begin{equation*}
q_{4,2} = 4 \cdot q_{3,1}
\end{equation*}

Hopefully, based on a similar line of thinking, you also agree with the general observation that, for enumerating the $k$-length arrangements of $n$ distinct things:

\begin{equation*}
q_{n,k} = n \cdot q_{n-1,k-1}
\end{equation*}

Let's consider what our "base case" will be here. If we have n letters available and a "length 1" ordering, we just choose a letter and have that be our "length-1 ordering". There are of course n letters we can choose from, so we have the base case: 
% TODO: Clarify "for all counting (or whatever) numbers $n$"

\begin{equation*}
q_{n,1} = n
\end{equation*}

% TODO: Need to discuss distinctness somehow (maybe in a footnote, or just later if you get to it)

% TODO: (Some explanation, maybe alluding to induction?)

(more explicitly)

\begin{equation*}
q_{n,k} = \prod_{i=n-(k-1)}^n = \prod_{i=n-k+1}^n
\end{equation*}

% TODO: Show the work? (split the product term, cancel, etc)

which we can also write, using our "factorial notation", as:

\begin{equation}
\label{eq:perms-n-k}
q_{n,k} = \frac{n!}{(n-k)!}
\end{equation}

% TODO: Some sort of philosophical wrap-up (maybe about extending problems? too cheesy?)


\subsection{Collecting things}

Finally, let's add another twist to the problem. Again, I'll select from the letters $a$, $b$, $c$, $d$ -- but this time, we don't care about orderings. Instead, we want to know how many \textit{collections} (or \textbf{combinations}) we can form. 
% TODO: Needs more
% e.g. (a,c) and (c,a) are to be considered not distinct

Let's write out all of them here:

\begin{gather*}
\{a, b\} \\
\{a, c\} \\
\{a, d\} \\
\{b, c\} \\
\{b, d\} \\
\{c, d\} \\
\end{gather*}

% TODO: Explain this observation
% ("First thing to see":)
% (One key thing to see: The "subproblems" are no longer equivalent (and are actually sort of dependent on one another -- find a good way to phrase this).)

Let's build off our previous sections' work. In some sense, we'd like to see how much we're "over-counting". 

For example, let's say we were considering letters $a$ and $b$. If we include both $(a, b)$ and $(b, a)$ in the count, instead of simply the collection $\{a, b\}$, would be over-counting this collection by a factor of 2. 

As another example: If we had the letters $b$, $c$, and $d$ (for our collection $\{b, c, d\}$), we would have the arrangements:

\begin{gather*}
(b, c, d) \\
(b, d, c) \\
(c, b, d) \\
(c, d, b) \\
(d, b, c) \\
(d, c, b) \\
\end{gather*}

Here, we're over-counting by a factor of 6.

% Possible TODO: Use this verbiage?: (So what can we do? We eliminate all the duplicate possibilities.)

In fact, hopefully the pattern is clear. If we are considering a collection of size $k$, then we are over-counting by the "number of orderings from $k$ things", which is simply ($k!$).\footnote{This sentence deserves an explanation mark, but that would cause confusion.} 

Let's incorporate this into our final observation. Let $c_{n,k}$ be the number of collections we can form of size $k$, from $n$ things. To account for our "over-counting" from the previous section's problem, we have

\begin{equation*}
c_{n,k} = \frac{q_{n,k}}{k!}
\end{equation*}

Substituting our previous section's result (Equation \ref{eq:perms-n-k}) gives us:

\begin{equation}
c_{n,k} = \frac{n!}{(n-k)! k!}
\end{equation}

% TODO: Briefly mention for what n and k values it makes sense
% Requires (either now, or probably earlier) mention of 0 factorial

% TODO: Mention binomial notation (and perhaps "nCk" notation)

\begin{exercise}
\label{ex:binom-coeff-symmetry}
Briefly prove that $c_{n,k} = c_{n,n-k}$.

(While the proof is short, the consequences are quite interesting. For example, if I have 20 distinct things to choose from, the number of ways to make collections of 3 things is equal to that of making collections of 17 things!)
% Hint: Basically substitute n-k for n
% TODO: Mention in solutions of just thinking about it as the collection and its "complement"
\end{exercise}



\subsection{(Example problem -- balls in urns)}

\subsection{Pascal's triangle}

% TODO: Preface with something (even as simple as the "fifth tale")

Consider the following "triangle" of numbers:

% TODO: Insert standard Pascal's triangle (for a few rows)
% TODO: Mention (maybe in terms/references and/or footnotes) that it's often called Pascal's triangle

Each number has an interesting property: it is the sum of the two numbers "above" it in the triangle. The exceptions are the numbers on the two "edges" of the triangle, which are all 1s.

Can we find a "formula" that will give us each number in the triangle?

% TODO?: space/break

% Note: In this section, we won't start by numbering indices the "conventional" way. Basically we'll sort of "discover" that the binomial coefficients have the properties, and realize that we have to do an index adjustment. (This sort of gives a better sense of discovery and refining observations, imo.) 

Let's try coming up with some notation to communicate about each "spot" in the triangle. We'll start numbering the rows from the top of the triangle downward, from 1, 2, 3, ... onwards. (We'll call this index $n$.) Then, in each row of the triangle, we'll number the leftmost number as 1, the one to its right as 2, and so on. (We'll call this index $k$.) Then we'll let $a_{n,k}$ denote each such number.

So our triangle looks something like this:

% TODO: Insert "Pascal's triangle" with a_{n,k} enumerated by n and k (so a_{1,1} at top, a_{2,1} and a_{2,2} on the second row, etc.

There are a few observations we can make here:

\begin{itemize}
\item First, for any given row $n$, the second index ($k$) here is always at least 1, and at most $n$. In other words, in any given row $n$, $a_{n,1}$ is the leftmost term in the row, and $a_{n,n}$ is the rightmost. 
\item In addition, based on how the triangle looks, it seems like its left and right edges are all 1s. Using our notation, this means that for all counting numbers $n \geq 1$, we have $a_{n,1} = 1$, and $a_{n,n} = 1$ as well. (This acts sort of as a "base case", for now.)
\item It also appears that the triangle is "symmetric" - if I were to draw a line down the triangle, the left side is a mirror image of the right, for every term. Using our notation -- and being a bit careful with our indices -- it looks as though, for every row $n$, and for each possible index $k$ (basically $1 \leq k \leq n$) we have $a_{n,k} = a_{n,(n+1) - k}$. 
% TODO: Figure - draw this?

\item We need to account for our "sum" relation -- in other words, each number on the inside of the triangle should be the sum of the two numbers "above" it. Using our notation, and thinking about our indices carefully, gives that for all counting numbers $n \geq 3$, and all counting numbers $k$ where $2 \leq k \leq n-1$: \footnote{Note that at $n = 1$ and $n = 2$, all numbers of the triangles are on the edges, and are covered by the base case mentioned previously.}

% OLD FOOTNOTE: \footnote{Note that, as the statement stands, this statement is meaningless at $n=1$ or $n=2$, because this would require $2 \leq k \leq 0$ and $2 \leq k \leq 1$, respectively. TODO: Philosophy on vacuous statements?}

\begin{equation}
\label{ex:pascal-rule-mys}
a_{n,k} = a_{n-1,k-1} + a_{n-1,k}
\end{equation}
\end{itemize}

This last relation seems like a particularly weird one to crack. Unlike previous example, it's a recursive relationship that now depends on \emph{two} index variables.

\subsubsection{(Searching)} 

Sometimes it helps to find patterns and connections with what we've learned before. 

We've seen one double-indexed sequence previously in the chapter -- the terms $c_{n,k}$, which we used to count the number of ways to make collections of size $k$, from $n$ distinct things.

Could this have any connection? From Exercise \ref{ex:binom-coeff-symmetry}, we know that $c_{n,k}$ has a similar "symmetry" property. 

What about $c_{n,k}$'s "base case"? We didn't define $c_{n,k}$ recursively, but do any particular values occur at "edge cases", like when $k = 0$ or when $k = n$, or when $n = 0$?

\begin{exercise}
\label{ex:binom-coeff-cn0}
Show that for all counting numbers $n \geq 0$, $c_{n,0} = 1$.
\end{exercise}

\begin{exercise}
Show that for all counting numbers $n \geq 0$, $c_{n,n} = 1$.

(Hint: You could repeat the strategy of Exercise \ref{ex:binom-coeff-cn0}, but could you use Exercise \ref{ex:binom-coeff-symmetry} as a shortcut?)
\end{exercise}


\subsubsection{(Closer)} 

It seems like $c_{n,k}$ is giving promising results so far. It shares the symmetry and "base case" behavior with our mystery terms $a_{n,k}$, except the indices seem a bit off.

%What if we fixed that problem?

What about this "sum" property described in Equation \ref{ex:pascal-rule-mys}? In theory, it would be nice if the numbers for collections obeyed some rule. In other words, for \emph{some} suitable choice of $n$ and $k$, we'd like it to be true that $c_{n,k} = c_{n-1,k-1} + c_{n-1,k}$.

What intuition can we develop, based on our notion of the "collections" problem? Well, let's say we wanted to find all the ways to collect $k$ things from $n$ distinct things. 

Suppose that there were a special element we had in mind. (Let's say that the elements are the numbers $1, 2, ..., n$, and that a particular one is our "lucky number".\footnote{13 is always a good choice, assuming $n \geq 13$.})

So we can divide our $k$-collections into the following cases:

\begin{enumerate}
\item Those that have our lucky number
\item Those that don't have our lucky number
\end{enumerate}

How many collections have our lucky number? Well, if our lucky number is already chosen, then it is one of the $k$ elements -- so, we have $k-1$ more to select. Also, since we already selected it from our $n$ elements, we now have $n-1$ elements to choose from. Hence, counting up all the ways, there are $c_{n-1,k-1}$ collections that have our lucky number.

How many don't have our lucky number? Unlike in our previous case, we haven't chosen it yet -- so we have $k$ more elements to select. However, we've now "blacklisted" our lucky number from the $n$ elements we can choose from, so we can only choose from $n-1$ of them now. Hence, there are $c_{n-1,k}$ collections that have our lucky number.

Well, since all collections we're interested in either have our lucky number or don't, and the total is $c_{n,k}$, it seems that this relationship works out!\footnote{With a bit more care with the indices, this would be a full-on bijective proof, like the balls problem above!}

So our "intuition" (or, "almost bijective proof") hints to us that $c_{n,k}$ might have the "sum property" that we desire!

Let's try to prove it formally. We'll actually give an algebraic proof below, and be a bit more rigorous with what the valid values of $n$ and $k$ are. We'll call this a \textbf{Theorem} -- basically, a statement proven rigorously -- and it will be one of many useful statements we'll build up and rely on in the book.

% TODO: (Explain that it's a theorem and we'll call them that)

% (Note that we'll eventually clarify the results outside these n and k bounds)

\begin{theorem} 
\label{th:pascal-binom-coeff}
For $n \geq 0$ and $0 \leq k \leq n-1$, 
\begin{equation}
c_{n+1,k+1} = c_{n,k} + c_{n,k+1}
\end{equation} 

\end{theorem}
\begin{proof}
Starting from the right side, 

\begin{align*}
c_{n,k} + c_{n,k+1} &:= \frac{n!}{(n-k)! k!} + \frac{n!}{(n-(k+1))! (k+1)!} \\
&= \frac{n!}{(n-k)! k!} + \frac{n!}{(n-k-1)! (k+1)!} \\
&= \frac{k+1}{k+1} \cdot \frac{n!}{(n-k)! k!} + \frac{n-k}{n-k} \cdot \frac{n!}{(n-k-1)! (k+1)!} && (\text{"Multiplying by 1"}) \\
&= \frac{ (k+1) \cdot n!}{(n-k)! (k+1)!} + \frac{n-k}{n-k} \cdot \frac{n!}{(n-k-1)! (k+1)!} && (\text{since $(k+1)! = (k+1) \cdot k!$}) \\
&= \frac{ (k+1) \cdot n!}{(n-k)! (k+1)!} + \frac{(n-k)! n!}{(n-k)! (k+1)!} && (\text{since $(n-k)! = (n-k) \cdot (n-k-1)!$}) \\
&= \frac{ (k+1) \cdot n! + (n-k)! n!}{(n-k)! (k+1)!} && \text{(Combine fraction)}\\
&= \frac{ (k+1 + n-k) \cdot n!}{(n-k)! (k+1)!} && \text{(Factor out)}\\
&= \frac{ (n+1) \cdot n!}{(n-k)! (k+1)!} \\
&= \frac{ (n+1)!}{(n-k)! (k+1)!} && (\text{since $(n+1)! = (n+1) \cdot n!$}) \\
&= \frac{ (n+1)!}{((n+1)-(k+1))! (k+1)!} && (\text{"Adding 0"}) \\
&=: c_{n+1,k+1}\\
\end{align*}

\end{proof}

% TODO: Briefly explain the reverse "=:"

% TODO: Some philosophizing on the proof maybe? (It's mostly just factorial manipulation to get a common denominator)
% 	"This time, we combined the fraction..." (or something)
% 	Btw TODO: Could also recursively define factorial similarly, maybe in exercise? (maybe unnecessary, but you could mention it off-hand in the main first recursion exercise)

\begin{exercise}
In the proof of Theorem \ref{th:pascal-binom-coeff}, where did we rely on the fact that $n \geq 0$ and $0 \leq k \leq n-1$?
\end{exercise}


% TODO: Mention the edges and how they can be resolved, with the triangle in a "bath" of 0s, and how it relates to outside values of c_{n,k}. 
% (Actually do this after introducing the c_{n,k} pattern and our intuition for "how many ways to arrange/select things") (This is a nice way to finish off this subsection?)
% Have a subsubsection for it below
% 


\subsection{(Binomial expansion)}

We now present our final tale. What do patterned triangles and counting techniques have to do with factoring and expanding ordinary expressions? % TODO: Present this better

Let's look at a brief pattern. Suppose we have the expression $(x+y)^2$. How else can we write it? Can we get an expression that doesn't involve parentheses?

Well,

\begin{align*}
(x+y)^2 &= (x+y)(x+y) \\
&= x(x+y) + y(x+y) \\
&= x \cdot x + x \cdot y + y \cdot x + y \cdot y \\
&= x^2 + 2xy + y^2
\end{align*}

% TODO: Could also give the geometric view?

Seems like a mess to get to, but we get an expression in the end.

\begin{exercise}
Try using some actual values (for example, $x=3$ and $y=4$), to convince yourself that you get the same answer when evaluating $(x+y)^2$, as when evaluating $x^2 + 2xy + y^2$ directly. 
\end{exercise}

What about a more complicated expression, like $(x+y)^3$? We see that:

\begin{align*}
(x+y)^3 &= (x+y)(x+y)^2 \\
&= (x+y)(x^2+2xy+y^2) \\
&= x(x^2+2xy+y^2) + y(x^2+2xy+y^2) \\
&= x^3 + 2x^2y + xy^2 + x^2y + 2xy^2 + y^3 \\
&= x^3 + 2x^2y + x^2y + xy^2 + 2xy^2 + y^3 \\
&= x^3 + 3x^2y + 3xy^2 + y^3 \\
\end{align*}

Seems like even more of a mess! Yet, we were able to simply and get something here as well.

\begin{exercise}
Try finding a similar expression for $(x+y)^4$. 
\end{exercise}

% Want to separate the exercise from the solution for now
\newpage

The expressions just seem to get more and more complicated! Yet -- is there anything interesting in what the more \emph{general} expression $(x+y)^n$ looks like when "expanded" -- in other words, some sort of pattern dependent on $n$? 

Let's try writing what we know slightly differently:

\begin{align*}
(x+y)^2 &= 1 \cdot x^2 + 2 \cdot xy + 1 \cdot y^2 \\
(x+y)^3 &= 1 \cdot x^3 + 3 \cdot x^2y + 3 \cdot xy^2 + 1 \cdot y^3 \\
(x+y)^4 &= 1 \cdot x^4 + 4 \cdot x^3y + 6 \cdot x^2y^2 + 4 \cdot xy^3 + 1 \cdot y^4 \\
\end{align*}

These coefficients are the exact same as rows in our previous triangle!

Let's formulate this more specifically. First, let's rewrite the above equations as follows:

\begin{align*}
(x+y)^2 &= 1 \cdot x^2 y^0 + 2 \cdot x^1 y^1 + 1 \cdot x^0 y^2 \\
(x+y)^3 &= 1 \cdot x^3 y^0 + 3 \cdot x^2 y^1 + 3 \cdot x^1 y^2 + 1 \cdot x^0 y^3 \\
(x+y)^4 &= 1 \cdot x^4 y^0 + 4 \cdot x^3 y^1 + 6 \cdot x^2 y^2 + 4 \cdot x^1 y^3 + 1 \cdot x^0 y^4 \\
\end{align*}


First, it at least looks like $(x+y)^n$ will expand into a bunch of terms involving powers of $x$ and $y$, as follows:

\begin{equation*}
(x+y)^n = \sum_{k=0}^n \text{(something)} \cdot x^{n-k} y^k
\end{equation*}

What is that something? It looks to be, for each term, the corresponding $(n,k)$ coefficient in Pascal's triangle -- in other words, $c_{n,k}$. (!)

Does it work? Let's prove it. (Challenge: Try to prove it yourself before looking at the proof on the next page.)

\newpage

\begin{theorem} 
\label{th:binom-expand}
For $n \geq 0$, 
\begin{equation}
(x+y)^n = \sum_{k=0}^n c_{n,k} x^k y^{n-k}
\end{equation} 

\end{theorem}
\begin{proof}
We'll prove this using induction. Briefly looking at the base case, wee see that $(x+y)^0 = 1$, and

\begin{equation*}
\sum_{k=0}^0 c_{n,k} x^k y^{n-k} = c_{0,0} x^0 y^0 = 1 \cdot 1 \cdot 1 = 1
\end{equation*}

as well.

We now assume the statement is true for some value $n$, and show it is true at $n+1$:

\begin{align*}
(x+y)^{n+1} &= (x+y)(x+y)^n \\
&= (x+y) \sum_{k=0}^n c_{n,k} x^k y^{n-k} && \text{(inductive assumption)} \\
&= x \sum_{k=0}^n c_{n,k} x^k y^{n-k} + y \sum_{k=0}^n c_{n,k} x^k y^{n-k} \\
&= \sum_{k=0}^n c_{n,k} x^{k+1} y^{n-k} + \sum_{k=0}^n c_{n,k} x^k y^{n-k+1} \\
&= \sum_{k=1}^{n+1} c_{n,k-1} x^{(k-1)+1} y^{n-(k-1)} + \sum_{k=0}^n c_{n,k} x^k y^{n-k+1} \\
&= \sum_{k=1}^{n+1} c_{n,k-1} x^{k} y^{(n+1)-k} + \sum_{k=0}^n c_{n,k} x^k y^{(n+1)-k} \\
&= c_{n,n} x^{n+1} y^0 + \sum_{k=1}^{n} c_{n,k-1} x^{k} y^{(n+1)-k} \\
&\qquad+ \sum_{k=1}^n c_{n,k} x^k y^{(n+1)-k} + c_{n,0} x^0 y^{n+1} \\
&= c_{n,n} x^{n+1} y^0 + \sum_{k=1}^{n} (c_{n,k-1} + c_{n,k}) x^{k} y^{(n+1)-k} + c_{n,0} x^0 y^{n+1} \\
&= c_{n,n} x^{n+1} y^0 + \sum_{k=1}^{n} c_{n+1,k} x^{k} y^{(n+1)-k} + c_{n,0} x^0 y^{n+1} && \text{(Theorem \ref{th:pascal-binom-coeff})} \\
&= c_{n+1,n+1} x^{n+1} y^0 + \sum_{k=1}^{n} c_{n+1,k} x^{k} y^{(n+1)-k} + c_{n+1,0} x^0 y^{n+1} && \text{(They all equal 1)} \\
&= \sum_{k=0}^{n+1} c_{n+1,k} x^{k} y^{(n+1)-k} && \text{(Combine $k=n+1$ term from left, $k=0$ term from right)} \\
%&= \sum_{k=1}^{n+1} c_{n,k-1} x^{k} y^{n-k+1} + \sum_{k=1}^n c_{n,k} x^k y^{n-k+1} + c_{n,0} x^0 y^0 \\
%&= \sum_{k=1}^{n+1} (c_{n,k-1} + c_{n,k}) x^{k} y^{n-k+1} + c_{n,0} x^0 y^0 \\
%&= \sum_{k=1}^{n+1} c_{n+1,k} x^{k} y^{n-k+1} + c_{n,0} x^0 y^0 && \text{(Theorem \ref{th:pascal-binom-coeff})} \\
%&= \sum_{k=1}^{n+1} c_{n+1,k} x^{k} y^{n-k+1} + c_{n+1,0} x^0 y^0 && \text{(both equal 1)} \\
%&= \sum_{k=0}^{n+1} c_{n+1,k} x^{k} y^{n-k+1} \\
\end{align*}

\end{proof}

% TODO: Philosophizing


%%%%%%

% TODO: (Eventually some/more recursion stuff)
% section/subsection here?

\section{(Why are we talking about this?)}

% Key points here:
% 	- Sense of what it feels like to work through and discover things. The real scientific process is a lot more like this than (what's commonly presented)
% 	- We'll rely on all this later. (Throw out brief examples)
%	- Don't get discouraged. ("How could I possibly have come up with this?" syndrome) This is deliberately the hardest part, and hopefully by reading through this, you'll develop more of a sense at the end.



\newpage
\section{Problems}


% TODO: Have a few problems on changing indices
% (Maybe as part of the problem below, before the whole i vs n-i thing)


\begin{problem}
\label{defining-sigma}

% TODO: Either hint at sequences a bit more earlier, or add some detail here.

% SCRAP: We've seen that the sigma-notation is a helpful way to write down an extended sum. If we have some \emph{sequence}\footnote{We'll talk more formally about sequences in the next chapter.} (essentially some "thing" dependent on an index $i$ ranging from 1 through $n$)\footnote{Note that the sum doesn't necessarily have to have an $a_2$ term or terms beyond that -- for example, $\sum_{i=1}^1 a_i$ is simply equal to $a_1$.}:

% TODO: Explain "index variable" more, depending on previous content

% TODO: Explain the "define" notation footnote more?

We've seen that the sigma-notation is a helpful way to write down an extended sum, especially when each term in the sum is dependent on some sort of "index variable". We previously used this notation to (among other things) describe the sum of the integers from 1 through some counting number $n$. For example, if $n$ is 10, then:\footnote{The "$:=$" notation means "the left side is terminology, and we are \emph{defining} it to be equal to the right side.}

\begin{align*}
\sum_{i=1}^{10} i := 1 + 2 + 3 + 4 + 5 + 6 + 7 + 8 + 9 + 10 
\end{align*}

Let's more formally generalize this a bit. We'll define $a_i$ to be some quantity that depends on $i$. Then (taking $n$ to equal 10 again, for our example):

\begin{align*}
\sum_{i=1}^{10} a_i := a_1 + a_2 + a_3 + a_4 + a_5 + a_6 + a_7 + a_8 + a_9 + a_{10}
\end{align*}

For example, if $a_i := 3i$, then:

\begin{align*}
\sum_{i=1}^{10} a_i := 3 + 6 + 9 + 12 + 15 + 18 + 21 + 24 + 27 + 30
\end{align*}

Let's be even more specific and rigorous. We can \emph{define} sigma-notation rigorously, using recursion. Here is a recursive definition, assuming we want to start our index variable at 1:

% TODO: Use := notation here?

\begin{align*}
\sum_{i=1}^1 a_i &= a_1 \\
\sum_{i=1}^n a_i &= \left(\sum_{i=1}^{n-1} a_i\right) + a_n & \text{when } n > 1
\end{align*}

We see that the first equation is a "base case", and the second is a recursive relation. 

% TODO: May need to get into starting indices, and adding terms from the beginning

% TODO: Maybe the problems on changing indices should be here (with perhaps some context, e.g. "we can define b_i = a_{i+1}"


% TODO: Correct this statement based on context
We can now rigorously inspect and prove some properties that we've taken for granted before. For the following problems, let $\{a_i\}$ be any sequence. 


% TODO: We've never mentioned the i to n-i problem before. Give some context, spell out small cases, etc. 

\begin{enumerate}[(a)]
\item Prove that $\sum_{i=1}^{n-1} a_i = \sum_{i=1}^{n-1} a_{n-i}$ for integer $n \geq 2$. (Think about why this is true first.)
\end{enumerate}


\end{problem}


\begin{problem}
\label{power-2-sum}
% TODO: Give lead-up

Consider the following pattern:

\begin{align*}
1 + 1 &= 2 \\
1 + 1 + 2 &= 4 \\
1 + 1 + 2 + 4 &= 8 \\
1 + 1 + 2 + 4 + 8 &= 16 \\
...
\end{align*}


Another way of looking at it:

\begin{align*}
1 + 2^0 &= 2^1 \\
1 + 2^0 + 2^1 &= 2^2 \\
1 + 2^0 + 2^1 + 2^2 &= 2^3 \\
1 + 2^0 + 2^1 + 2^2 + 2^3 &= 2^4 \\
...
\end{align*}


Essentially, by summing up a bunch of powers of 2 in sequence (starting from 1), one just *almost* reaches the next power -- all we need is to add an extra 1!

% SCRAP: Essentially, by summing up a bunch of powers of 2 in sequence (starting from 1), one just *almost* reaches the next one!

Let's prove it. Prove that this pattern exists for all integer powers of 2 -- in other words, prove that $1 + \sum_{i=0}^{n-1} 2^i = 2^n$, for all integers $n \geq 1$.

\end{problem}

\begin{problem}
\label{sequence-recursive-sum}

Here's a bit of an odd sequence: Let the sequence $\{a_i\}$ be defined by

\begin{align*}
a_1 &= 1 \\
a_{n} &= \sum_{i=1}^{n-1} a_i
\end{align*}

In other words,

\begin{align*}
a_1 &= 1 \\
a_2 &= a_1 \\
a_3 &= a_1 + a_2 \\
a_4 &= a_1 + a_2 + a_3 \\
a_5 &= a_1 + a_2 + a_3 + a_4 \\
...
\end{align*}

Note that each term in the sequence is defined recursively on *all* the terms before it!

Find an explicit formula for $a_n$, and prove it. 

% TODO: Somewhere up there, in the actual material, explain recursion, explain recursive sequences, explain what it means to give explicit solution, give examples. This is a *really* important idea across tons of fields, and it's one that a lot of people have trouble grasping. Massive impact to be had here. </speech>

% Answer (without proof) in the hints
% HINT: Another exercise in this section may be very helpful... 
% (TODO: could just hint at it explicitly?)

\end{problem}



% This will be our "pierce the heavens" problem: a challenge that ideally incorporates a lot of what we've talked about. 
% 
% Things used in this problem:
%	- Recurrence/recursion
%	- Counting permutations with things in btwn (the "balls" exercise)
%	- Summation index shifting, term peeling, (various rules)
%	- Sum of row of pascal's triangle
%	- Commutativity of addition
%	- (Sum of i*2^i)
%	- Replacing n-i with i in sum
\begin{problem}
\label{composition-num-3s}

We'll call the sequence $(x_1, x_2, ..., x_k)$ a \textbf{composition} of $n$ (where $n$ is a counting number) if the numbers in the sequence sum to $n$ -- in other words, if:

\begin{equation*}
\sum_{i=1}^k x_i = n
\end{equation*}

For example, $(1,3,1)$ would be a composition of 5.

\begin{enumerate}[(a)]
\item How many compositions of $n$ of length $k$ are there, if we can only use nonnegative numbers? % Hint: Balls
\item How many compositions of $n$ of length $k$ are there, if we can only use positive numbers? % Hint: Consider (x_i - 1) for all i
\item How many compositions of $n$ are there in total, using positive numbers? % Hint: Pascal's triangle
\end{enumerate}

Here's a weird question: If I look at all of the positive-number compositions of $n$, how many times will I see the number 3? (Let's call this count $N(n)$.)

\begin{enumerate}[(a)]
\setcounter{enumi}{3}
\item What are $N(1)$, $N(2)$, and $N(3)$?
\item I claim that, if $n \geq 4$, then $N(n) = n2^{n-5}$. Prove this claim. 
\end{enumerate}

% I claim that, if I take $n \geq 4$, and look at every composition of $n$, I will see the number 3 exactly $n2^{n-5}$ times.



\end{problem}


\newpage
\section{Terms and References}

\section{Hints}

\newpage
\section{Solutions}

\subsection{Exercise \ref{sum-i2}}

% Note: This will be one of the first major exercises. Make sure the solution is detailed.

We're hoping to prove that:
\begin{align*}
\sum_{i=1}^{n} i^2 = \frac{n(n+1)(2n+1)}{6}
\end{align*}

First, let's see whether this statement is true at $n = 1$. On the left side, we see that:
\begin{align*}
\sum_{i=1}^{1} i^2 = 1^2 = 1
\end{align*}

And on the right side, we see that:
\begin{align*}
\frac{1(1+1)(2 \cdot 1+1)}{6} = \frac{1 \cdot 2 \cdot 3}{6} = \frac{6}{6} = 1
\end{align*}

So the statement holds at $n = 1$. Great!


Now for our "inductive step". Suppose the statement were true at $n = k$. In other words, suppose we knew that:
\begin{align*}
\sum_{i=1}^{k} i^2 = \frac{k(k+1)(2k+1)}{6}
\end{align*}

Let's try to now prove that the statement is true at $n = k + 1$. In other words, we wish to prove that:
\begin{align*}
\sum_{i=1}^{k+1} i^2 = \frac{(k+1)((k+1)+1)(2(k+1)+1)}{6}
\end{align*}

(Simplify)

\begin{align*}
\sum_{i=1}^{k+1} i^2 = \frac{(k+1)(k+2)(2k+3)}{6}
\end{align*}

(Work)

\begin{align*}
\sum_{i=1}^{k+1} i^2 &= \sum_{i=1}^{k} i^2 + (k+1)^2 \\
&= \frac{k(k+1)(2k+1)}{6} + (k+1)^2 && \text{(Using our "inductive assumption" that the statement is true at $n = k$)} \\
&= \frac{k(k+1)(2k+1) + 6(k+1)^2}{6} && \text{(Combine fractions)} \\
&= \frac{(k+1)\left[k(2k+1) + 6(k+1)\right]}{6} && \text{(Factor out $k+1$)} \\
&= \frac{(k+1)(2k^2 + k + 6k + 6)}{6} && \text{(Expand terms)} \\
&= \frac{(k+1)(2k^2 + 7k + 6)}{6} && \text{(Combine terms)} \\
&= \frac{(k+1)(k+2)(2k+3)}{6} && \text{(Factor)} \\
\end{align*}

Great! If the statement is true at $n = k$, then it is also true when $n = k + 1$. 

So "by induction", our statement is true when $n$ is any of the counting numbers. $\square$


% TODO: Be specific and say e.g. "induction on $n$"?

\subsection{Problem \ref{defining-sigma}, proving $\sum_{i=1}^{n-1} a_i = \sum_{i=1}^{n-1} a_{n-i}$ for $n \geq 2$}

We prove this claim using induction. 

The base case at $n = 2$ is clearly true, since $\sum_{i=1}^{2-1} a_i = a_1$, and $\sum_{i=1}^{2-1} a_{n-i} = a_1$ as well. 

Let's do the inductive step. We assume the statement is true at $n = k$, i.e. we assume $\sum_{i=1}^{k-1} a_i = \sum_{i=1}^{k-1} a_{k-i}$ -- and show that the statement is true at $n = k + 1$, i.e. we show that $\sum_{i=1}^{(k+1)-1} a_i = \sum_{i=1}^{(k+1)-1} a_{(k+1)-i}$.

We do this as follows:

\begin{align*}
\sum_{i=1}^{(k+1)-1} a_i &= \sum_{i=1}^{k} a_i \\
&= \sum_{i=1}^{k-1} a_i + a_k \\
&= \sum_{i=1}^{k-1} a_{k-i} + a_k && \text{Inductive assumption} \\
&= \sum_{i=1}^{k-1} a_{(k+1)-(i+1)} + a_{(k+1)-1} && \text{"Adding 0"} \\
&= \sum_{i=2}^{k} a_{(k+1)-i} + a_{(k+1)-1} && \text{Shifting summation index} \\
&= \sum_{i=1}^{k} a_{(k+1)-i} && \text{Combining "$i = 1$" term} \\
&= \sum_{i=1}^{(k+1)-1} a_{(k+1)-i} \\
\end{align*}

Hence, the inductive step holds, and therefore the claim holds for all integers $n \geq 2$. 

% TODO: For the "combining i = 1 term" step, need to show another property of sigma notation first. 
% (In fact, maybe this problem doesn't belong in the "rigorously defining sigma" stage...)


\subsection{Problem \ref{power-2-sum}}

We prove this claim using induction. 

The base case at $n = 1$ is true -- clearly, $1 + 2^0 = 2^1$. 

Let's do the inductive step. We assume the statement is true at $n = k$, i.e. we assume $1 + \sum_{i=0}^{k-1} 2^i = 2^k$ -- and show that the statement is true at $n = k + 1$, i.e. we show that $1 + \sum_{i=0}^{k} 2^i = 2^{k+1}$.

We do this as follows: 

% TODO: Maybe I'm being a bit overly explicit here

\begin{align*}
1 + \sum_{i=0}^{k} 2^i &= 1 + \sum_{i=0}^{k-1} 2^i + 2^k \\
&= 2^k + 2^k && \text{Inductive assumption} \\
&= 2 \cdot 2^k \\
&= 2^1 \cdot 2^k \\
&= 2^{k+1} \\
\end{align*}

Hence, the inductive step holds, and therefore the claim holds for all integers $n \geq 1$. 

\subsection{Problem \ref{sequence-recursive-sum}}

$a_n = 2^{n-2}$ for all $n \geq 2$. 

% SCRAP: We prove this claim using strong induction -- in other words, we will have a base case (here at $n = 2$), and to prove the claim for some $n = k$, we will assume that the statement is true for $n = 2$, ..., all the way up through $n = k - 1$. 

We prove this claim using \textbf{strong} induction. 

The base case at $n = 2$ is true, since:

\begin{align*}
\sum_{i=1}^{2-1} a_i &= a_1 \\
&= 1 && \text{(Value of $a_1$)} \\
&= 2^{2-2}
\end{align*}

We then prove the strong inductive step, proving that the statement is true for $n = k$, assuming that the statement is true for $n = 2$, ..., all the way up through $n = k - 1$.

\begin{align*}
a_k &= \sum_{i=1}^{k-1} a_i \\
&= a_1 + \sum_{i=2}^{k-1} a_i \\
&= 1 + \sum_{i=2}^{k-1} a_i && \text{(substitute value for $a_1$)} \\
&= 1 + \sum_{i=2}^{k-1} 2^{i-2} && \text{(strong inductive assumption)} \\
&= 1 + \sum_{i=0}^{(k-2)-1} 2^i && \text{(shifting summation index)} \\
&= 2^{(k-2)} && \text{(proved in Exercise \ref{power-2-sum})}
\end{align*}

Hence, the strong inductive step holds, and therefore the claim holds: $a_n = 2^{n-2}$ for all integers $n \geq 2$. 


\subsection{Problem \ref{composition-num-3s}}

As in our problem, let $N(n)$ be the number of times we see 3 in the compositions of $n$. 

Ideally, we'd like to find a recurrence relation for $N(n)$ -- that way, we could hopefully give an induction proof, or at least find some way to take advantage of our recursion. We'll do this, but first some preliminary work.

\subsubsection{A new term}

Let $N_k(n)$ be the number of times we see 3 among compositions \emph{of length $k$}. A few examples of what this looks like:

\begin{itemize}
\item The only composition of 4 of length 1 is simply $(4)$ -- in other words, the sequence containing only the number 4. We have no 3s here, so $N_1(4) = 0$.
\item The only compositions of 4 of length 2 are $(1,3)$, $(2,2)$, and $(3,1)$. We see 2 3s in total among them, so $N_2(4) = 2$.
\item Similar to our first example, the only composition of 3 of length 1 is simply $(3)$. We have a single 3 here, so $N_1(3) = 1$.
\item The only compositions of 3 of length 2 are $(1,2)$ and $(2,1)$. No 3s here, so $N_2(3) = 0$.
\item We can't have any compositions of $n < 3$ that contain 3, so $N_k(n) = 0$ for all $k$ whenever $n < 3$. (Makes sense -- from part (d), we know that $N(n) = 0$ itself when $n < 3$.)
% TODO: More here, e.g. the N_k(n) for n < 3
\end{itemize}


The number of times we'll see 3 in total is simply the sum of times over all lengths $k$ -- in other words:

\begin{equation*}
N(n) = \sum_{k=1}^{n} N_k(n)
\end{equation*}

Two key observations help explain this expression, and also let us simplify this a bit:

\begin{itemize}
\item We won't see a 3 in any composition of length $n$, because the only such composition is (1, 1, 1, ..., 1) -- essentially $n$ 1s. Therefore, $N_n(n) = 0$ for all counting numbers $n$.
\begin{itemize}
\item For similar reasons, it also follows that $N_k(n) = 0$ whenever $k \geq n$, because for $k > n$, there are no positive-number compositions at all of length $k$ for $n$. (This isn't relevant in this section, but will be important later.)
\end{itemize}
\item If $n \geq 4$, then we won't see a 3 in any composition of length $1$, because the only such composition consists of $n$ itself -- and if $n \geq 4$, then $n \neq 3$. Therefore, $N_1(n)$ = 0. 
\end{itemize}

So simplifying the above equation gives:
\begin{align*}
N(n) &= \sum_{k=1}^{n} N_k(n) \\
&= N_1(n) + \sum_{k=2}^{n-1} N_k(n) + N_n(n) \\
&= 0 + \sum_{k=2}^{n-1} N_k(n) + 0 \\
\end{align*}

and therefore, for $n \geq 4$,

\begin{equation}
\label{composition-num-3s-n-nk}
N(n) = \sum_{k=2}^{n-1} N_k(n)
\end{equation}

\subsubsection{Recurrence on $N_k(n)$}

Instead of constructing a recurrence relation for $N(n)$ immediately, we'll first construct a recurrence relation for $N_k(n)$. Therefore, we'll be looking at sequences of the form $(x_1, x_2, ..., x_k)$ whose terms sum to $n$.

We'll establish this relation for $k \geq 2$ and $n \geq 4$. The base cases (some of which have been discussed directly or indirectly) are:

\begin{enumerate}
\item $N_k(n) = 0 \quad \text{when } k \geq n$ \label{eqbc-3s-1}
\item $N_1(n) = 0 \quad \text{when } n \geq 4$  \label{eqbc-3s-2}
\item $N_1(2) = 0$  \label{eqbc-3s-3}
\item $N_1(3) = 1$  \label{eqbc-3s-4}
\item $N_2(3) = 0$ \label{hooo}  \label{eqbc-3s-5}
\end{enumerate}


We'll split up our counting into two parts:
\begin{enumerate}
\item How many 3s we see among the first terms (i.e. all the $x_1$s of our compositions)
\item How many 3s there are in the compositions of the form $(x_2, ..., x_k)$ -- in other words, the compositions from before, with the first terms chopped off.
\end{enumerate}

We'll count the latter first. In each composition of $n$, the first term $x_1$ could be any value of $i$ from 1 through $n$. However, since $k \geq 2$, we cannot have $x_1 = n$ (since $x_2, ..., x_k$ would then all have to be 0, and we are only using positive numbers in our composition). 

So $x_1$ could be any value of $i$ from 1 through $(n-1)$. In each such case, the sequence $(x_2, ..., x_k)$ would now be a composition of $(n-i)$, of length $(k-1)$. The number of 3s seen collectively among these compositions would be $N_{k-1}(n-i)$, and we sum over all $i$ to get their total contribution.

We now count the former, i.e. the number of 3s we see in the $x_1$s. (This occurs when $i = 3$ in the above case.) We now know that we'll gain one 3 from each of these compositions. 

Now the number of such compositions $(x_1, x_2, ..., x_k)$, where $x_1 = 3$, is simply given by the number of compositions $(x_2, ..., x_k)$ of $(n-3)$ (and as before, of length $(k-1)$). 

How many of these are there? From part (b), the number of compositions of $n$ of length $k$ is $\binom{n-1}{k-1}$. Therefore, substituting our actual values gives $\binom{(n-3)-1}{(k-1)-1} = \binom{n-4}{k-2}$ such compositions. Since each of these compositions will give us one 3 in the $x_1$ term, we'll gain $\binom{n-4}{k-2}$ 3s.

Combining all of this information gives us a recurrence relation:

\begin{equation} 
\label{composition-num-3s-nk-recurrence}
N_k(n) = \binom{n-4}{k-2} + \sum_{i=1}^{n-1} N_{k-1}(n-i)
\end{equation}


\subsubsection{Recurrence on $N(n)$}

Now that we have something for $N_k(n)$, let's see what we can do with $N(n)$. 

Starting from Equation \ref{composition-num-3s-n-nk}, we have (for $n \geq 4$ and $k \geq 2$):

\begin{align*}
N(n) &= \sum_{k=2}^{n-1} N_k(n) \\
&= \sum_{k=2}^{n-1} \left( \binom{n-4}{k-2} + \sum_{i=1}^{n-1} N_{k-1}(n-i) \right) && \text{(Equation \ref{composition-num-3s-nk-recurrence})} \\
&= \sum_{k=2}^{n-1} \left( \binom{n-4}{k-2} + \sum_{i=1}^{n-1} N_{k-1}(i) \right) && \text{(Problem \ref{defining-sigma})} \\
&= \sum_{k=2}^{n-1} \binom{n-4}{k-2} + \sum_{k=2}^{n-1} \sum_{i=1}^{n-1} N_{k-1}(i) \\
&= \sum_{k=0}^{n-3} \binom{n-4}{k} + \sum_{k=2}^{n-1} \sum_{i=1}^{n-1} N_{k-1}(i) && \text{(Shift index)} \\
&= \sum_{k=0}^{n-4} \binom{n-4}{k} + \binom{n-4}{n-3} + \sum_{k=2}^{n-1} \sum_{i=1}^{n-1} N_{k-1}(i) \\
&= 2^{n-4} + \binom{n-4}{n-3} + \sum_{k=2}^{n-1} \sum_{i=1}^{n-1} N_{k-1}(i) && \text{(Sum of row in Pascal's triangle)} \\
&= 2^{n-4} + \sum_{k=2}^{n-1} \sum_{i=1}^{n-1} N_{k-1}(i) && \text{(Binomial coefficient defn -- term is 0)} \\
&= 2^{n-4} + \sum_{i=1}^{n-1} \sum_{k=2}^{n-1} N_{k-1}(i) && \text{(Commutativity of addition!)} \\
&= 2^{n-4} + \sum_{i=1}^{n-1} \sum_{k=1}^{n-2} N_{k}(i) && \text{(Shift index)}
\end{align*}

% TODO: Possible philosophizing on the commutativity trick

At this point, we want to make sure we handle our base cases correctly, since there's a lot going on. Continuing, we have:

\begin{align*}
N(n) &= 2^{n-4} + \sum_{i=1}^{n-1} \sum_{k=1}^{n-2} N_{k}(i) \\
&= 2^{n-4} + \sum_{i=1}^{n-1} \left( \sum_{k=1}^{i-1} N_{k}(i) + \sum_{k=i}^{n-2} N_{k}(i) \right) && \text{(Split sum)} \\
&= 2^{n-4} + \sum_{i=1}^{n-1} \sum_{k=1}^{i-1} N_{k}(i) && \text{(Base case \ref{eqbc-3s-1})} \\
&= 2^{n-4} + \sum_{i=2}^{n-1} \sum_{k=1}^{i-1} N_{k}(i) && \text{(Empty inside sum at $i=1$)} \\
&= 2^{n-4} + \left( N_1(2) \right) + \left( N_1(3) + N_2(3) \right) + \sum_{i=4}^{n-1} \sum_{k=1}^{i-1} N_{k}(i) && \text{(Split and expand sums at $i=2,3$)} \\
&= 2^{n-4} + 0 + \left( 1 + 0 \right) + \sum_{i=4}^{n-1} \sum_{k=1}^{i-1} N_{k}(i) && \text{(Base cases \ref{eqbc-3s-3}, \ref{eqbc-3s-4}, \ref{eqbc-3s-5})} \\
&= 2^{n-4} + 1 + \sum_{i=4}^{n-1} \sum_{k=1}^{i-1} N_{k}(i) \\
&= 2^{n-4} + 1 + \sum_{i=4}^{n-1} \sum_{k=2}^{i-1} N_{k}(i) && \text{(Base case \ref{eqbc-3s-2})} \\
&= 2^{n-4} + 1 + \sum_{i=4}^{n-1} N(i) && \text{(Equation \ref{composition-num-3s-n-nk} again!)} \\
\end{align*}

This is promising -- we now have a recurrence relation for $N(n)$ itself! (In fact, it looks sort of like that from Problem \ref{sequence-recursive-sum}, with different notation and a few extra terms thrown in.)


\subsubsection{Induction}

We now proceed to the final part of our proof. A reminder of what we want to prove: if $n \geq 4$, then $N(n) = n2^{n-5}$.

We'll use strong induction. For our base case at $n = 4$, we simply go through all compositions. They are:
\begin{gather*}
(1, 1, 1, 1) \\
(2, 1, 1) \\
(1, 2, 1) \\
(1, 1, 2) \\
(2, 2) \\
(1, 3) \\
(3, 1) \\
(4)
\end{gather*}

This gives us 2 3s. And at $n = 4$,
\begin{equation*}
n2^{n-5} = 4 \cdot 2^{4-5} = 4 \cdot 2^{-1} = 2
\end{equation*}

So the base case is true.

We then prove the strong inductive step, proving that the statement is true at $n$, assuming the statement is true for values $4, 5, ..., (n-1)$:\footnote{It's slightly different here to be working with $n$ directly (as opposed to having another placeholder variable), but hopefully you agree this is valid.}

\begin{align*}
N(n) &= 2^{n-4} + 1 + \sum_{i=4}^{n-1} N(i) \\
&= 2^{n-4} + 1 + \sum_{i=4}^{n-1} i2^{i-5} && \text{(Strong inductive assumption)} \\
&= 2^{n-4} + 1 + 2^{-5} \sum_{i=4}^{n-1} i2^{i} \\
&= 2^{n-4} + 1 + 2^{-5} \left(\sum_{i=1}^{n-1} i2^{i} - \left( 3 \cdot 2^3 + 2 \cdot 2^2 + 1 \cdot 2^1 \right) \right) \\
&= 2^{n-4} + 1 + 2^{-5} \left(\sum_{i=1}^{n-1} i2^{i} - (24 + 8 + 2) \right) \\
&= 2^{n-4} + 1 + 2^{-5} \left(2 + 2^{(n-1)+1}((n-1)-1) - (24 + 8 + 2) \right) \\
&= 2^{n-4} + 1 + 2^{-5} \left(2 + 2^{n}(n-2) - (24 + 8 + 2) \right) \\
&= 2^{n-4} + 1 + 2^{-5} \left(2^{n}(n-2) - (24 + 8) \right) \\
&= 2^{n-4} + 1 + 2^{-5} \left(2^{n}(n-2) - 2^5 \right) \\
&= 2^{n-4} + 1 + 2^{n-5}(n-2) - 1 \\
&= 2^{n-4} + 2^{n-5}(n-2) \\
&= 2^{n-4} + n2^{n-5} - 2 \cdot 2^{n-5} \\
&= 2^{n-4} + n2^{n-5} - 2^{n-4} \\
&= n2^{n-5}
\end{align*}

Hence, our strong inductive step holds, and therefore our statement holds: for $n \geq 4$, $N(n) = n2^{n-5}$. $\square$

% TODO: Mention other solution possibilities (with different overlapping base cases, go through possible work there - maybe pull out previous commits?)

