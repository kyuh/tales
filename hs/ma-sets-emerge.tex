%!TEX root = tales-main.tex


% Big theme here: Emergent properties
%	(i.e. what happens when we have this property (here, among members of sets)
%	we can get some interesting consequence (e.g. dimension))

\chapter{(Sets and Emergence)}

% Sth: "This might be the most boring way to start a chapter. In the past, we've talked about counting things -- here, we'll be talking about, quite literally, "things" (or more properly, collections of things)"

The start of this chapter will be particularly boring. (Sorry.)

So far, we've talked about counting things, adding things, mapping things to other things, and so on.

In this chapter, we'll just be talking about things. More specifically, we'll be talking about collections, or \textbf{sets}, of things.

% TODO: Say something like "This sounds boring. But we'll see that little quirks in our collections will give us fascinating properties -- cool things that will seem to spring out of faint air. We'll then show that 
% TODO: Say something like "but there is something cool that happens"
% TODO: Decide on whether to give a sneak preview here (like for integration chapter)

\section{(Sets intro)}

What do we mean by a "set of things"? Here are some examples:

\begin{itemize}
\item The set containing the numbers 1, 2, and 3. 
\begin{itemize}
\item We'll write this as $\{1, 2, 3\}$.
\end{itemize}
\item The set containing the numbers 0.6, 1/3, and 77.
\begin{itemize}
\item Similarly, we can write this as $\{0.6, 1/3, 77\}$.
\end{itemize}
\item The set containing all counting numbers. 
\begin{itemize}
\item Unlike the previous sets, this set has an \emph{infinite} number of elements. 
\item From here on, we'll denote this as $\mathbb{N}$. 
\end{itemize}
\item The set containing all counting numbers divisible by 3.
\item The set containing the numbers -1 and 1 (which we'll write as $\{-1, 1\}$). 
\item The set containing all the numbers $x$ that satisfy the equation $x^2 = 1$.
\begin{itemize}
\item This set is \emph{equivalent} to the previous one, $\{-1, 1\}$.
\end{itemize}
\item The set containing the colors red, yellow, green, and blue.
\begin{itemize}
\item We'll write it as $\{\text{red}, \text{yellow}, \text{green}, \text{blue}\}$.
\end{itemize}
\item The set containing all real numbers.
\begin{itemize}
\item We've written this before as $\mathbb{R}$. 
\end{itemize}
\item The set of all functions that map $\mathbb{R}$ to $\mathbb{R}$, i.e. the set of all functions $f: \mathbb{R} \rightarrow \mathbb{R}$
\item The set of all \emph{linear} functions from $\mathbb{R}$ to $\mathbb{R}$.
\item The set of all functions from $\mathbb{R}$ to $\mathbb{R}$ that are continuous over some interval $\left[a, b\right]$.
\end{itemize}
% TODO: Need to explain the interval notation


Already, the notion of a set is \emph{incredibly} general. How can we make sense of them?

% TODO: Something like (maybe earlier than this): We'll start with a few interesting cases, and then move into some general statements
% 	Possible example (or maybe culminating problem): Fixed-point iteration, and moving toward Picard iteration

\subsection{What's in a set?}

% (Counting numbers, divisibility, prime numbers)

Let's say we've described our set somehow. How do we know what's in it?

First, let's look at one of the first sets we ever saw: the set of counting numbers. 

We defined it using two "rules":
\begin{enumerate}
\item 0 is in the set.
\item If $k$ is in the set, then $k+1$ is as well. 
\end{enumerate}
\hfill

% TODO: Mention some key properties?
%	- There is no number "between" successive integers. (Important later.)

% TODO: Correct cross/chapter numbers and problems
A related set is the set of \textbf{even} counting numbers\footnote{which we saw in Exercise \ref{ex:even-numbers}} -- in other words, the numbers 0, 2, 4, 6, 8, ... and so on.

This set is "contained" in (or is a \textbf{subset} of) the counting numbers -- in other words, every element in the even numbers is also in the counting numbers.

There are lots of ways to define the even numbers. One way is to use a very similar definition as with the counting numbers, with a slight twist:
\begin{enumerate}
\item 0 is in the set.
\item If $k$ is in the set, then $k+2$ is as well. 
\end{enumerate}

But another way to define them is the set of numbers $n$ where $n$ is a counting number and $n$ is "divisible" by 2. 

What does that mean, precisely? We can rewrite the "divisibility" condition by noting that saying "$n$ is divisible by 2" is equivalent to saying "there exists a counting number $q$ such that $n = 2q$". 

\begin{exercise}
Let's make sure that our new "divisibility" definition makes sense. Try the following things:
\begin{itemize}
\item 4 is an even number. Does this definition work out? What number $q$ satisfies this property?
\item 3 is not an even number. Does it make sense that there is no such number $q$? Why?
\end{itemize}
\end{exercise}

\hfill

With that, we have a second definition for the even numbers: The numbers $n \in \mathbb{N}$ where $n = 2q$ for some \emph{counting number} $q$. 


\subsubsection{(Divisibility)}

This definition is very powerful! All of a sudden, we can easily see whether a number is in the set of evens or not -- either find an appropriate counting number $q$, or show that such a $q$ doesn't exist!

Let's generalize our definition a bit. We'll denote the set of numbers divisible by $k$, for some counting number $k$ (so there will be a different set for each $k$). 

To define each one, we'll say that a counting number $n$ is in the $k$-divisible set if there exists a counting number $q$, such that $n = kq$.

For example:
\begin{itemize}
\item The set of numbers divisible by 3 -- in other words, $\{0, 3, 6, 9, ...\}$. 
\item The set of numbers divisible by 5 -- in other words, $\{0, 5, 10, 15, ...\}$. 
\end{itemize}

% TODO: Some not-boring divisibility problems

\begin{theorem}
\label{th:div3-10n-1}
$(10^n - 1)$ is divisible by 3, for all counting numbers $n \geq 1$. 
\end{theorem}
\begin{proof}
We'll prove this using induction. 

In our base case, we see that $10^1 - 1 = 9$, which is divisible by 3 (since $3 \cdot 3 = 9$). 

For our inductive step, we'll assume that, for some value $n$, there exists a counting number (we'll call it $q_n$) such that $3q = 10^n - 1$. We'll then show that there exists a (likely different) integer $q_{n+1}$ such that $3q_{n+1} = 10^{n+1} - 1$. We see that:

\begin{align*}
10^{n+1} - 1 &= 10 \cdot 10^n - 1 \\
&= (9 + 1) \cdot 10^n - 1 \\
&= 9 \cdot 10^n + 10^n - 1 \\
&= 9 \cdot 10^n + 3q_n \\
&= 3 \cdot 3 \cdot 10^n + 3q_n \\
&= 3 \cdot (3 \cdot 10^n + q_n) \\
\end{align*}

From our inductive assumption, $q_n$ is an integer. 
% TODO: Mention that we won't prove "closure" too formally yet

\end{proof}

\subsubsection{(Primes)}

% TODO: More intro
As it turns out, there are some numbers that are not divisible by \emph{any} number, other than 1 and itself. We call these the \textbf{prime numbers}. 

Some of the first few prime numbers (which you can verify) are 2, 3, 5, 7, 11, 13, 17, 19. %TODO: State better

% TODO: FTA
% TODO: Some observations:
%	- All prime numbers are odd, except for 2. 

\begin{theorem}
$\mathbb{P}$ is infinitely big. 
\end{theorem}
\begin{proof}
We'll do a "proof by contradiction". % TODO: Explain (if this is the first time)

Suppose $\mathbb{P}$ had finite size. Let

\begin{equation*}
x = \prod_{p \in \mathbb{P}} p
\end{equation*}
% TODO: Maybe explain this notation if it hasn't come up before

In other words, consider the number $x$ formed by multiplying out all of the prime numbers in $\mathbb{P}$. (Since there are only finitely many elements in $\mathbb{P}$, this product is well-defined, and $x$ is just another number.) 

Since we simply multiplied all of our prime numbers, $x$ is divisible by any $p$ in $\mathbb{P}$.\footnote{Using our traditional definition of divisibility, we know that for any $p$, $x = q_p p$, where $q_p = \prod_{p' \in (\mathbb{P} - \{p\})} p'$ (so $q_p$ is a counting number).}

Now, let:

\begin{equation*}
y = 1 + x
\end{equation*}

Since (for every $p$) $x = q_p p$, we have $y = q_p p + 1$. Therefore, by (TODO), $y$ cannot be divisible by any such $p$.
% TODO: Insert some stuff (using previous theorems) about how this can't be divisible by any of the prime numbers p, 

But then we now have a prime number that wasn't in $\mathbb{P}$. Hence, we have a contradiction. Therefore, $\mathbb{P}$ cannot be finitely big; in other words, there must be infinitely many prime numbers.
\end{proof}

% TODO: Insert that Euler function problem?



\newpage

\begin{exercise}
What are the intersection and union of...
\begin{enumerate}[(a)]
\item ...the set $\{1, 2, 3\}$ and the set $\{2, 3, 4\}$?
\item ...the "null set" (the set with nothing in it) and any other set?
\item ...the set of all even integers, and the set of all odd integers?
\end{enumerate}
\end{exercise}

\begin{exercise}
What is the intersection of...
\begin{enumerate}[(a)]
\item ...the set of prime numbers, and the set of even numbers?
\item ...the set of integers divisible by 2, and the set of integers divisible by 3?
\end{enumerate}
\end{exercise}

% TODO: Need to have defined prime numbers at some point



\section{Structure}



\section{Problems}

%%%%%%%% Fixed-point iteration problems

\begin{problem}
\label{pr:fp-intro}
For any function $f$, we call $c$ a \textbf{fixed point} of $f$ if $f(c) = c$. 

(For functions involving real numbers, imagine fixed points as those points where the graph of $f(x)$ touches or crosses the line $y = x$.)

% TODO: Insert some figure here

\begin{enumerate}[(a)]
\item Find the fixed points of the following functions. (Assume $f$ maps real numbers to real numbers in each of the below cases.)
\begin{enumerate}[i.]
\item $f(x) = 3$
\item $f(x) = 2x + 1$
\item $f(x) = x^2$
\item $f(x) = x$
\item $f(x) = 1$ when $x$ is rational, and 0 when $x$ is irrational


\end{enumerate}

For the purposes of this problem, let $f_2(x)$ = $f(f(x))$, $f_3(x) = f(f(f(x)))$, and so on. More formally, define let $f_1(x) = f(x)$, and $f_k(x) = f(f_{k-1}(x))$.

\item Prove that, if $c$ is a fixed point of $f$, then $c$ is also a fixed point of $f_k$ for all counting numbers $k \geq 1$. (This is a really short proof and may seem obvious, but it will play a key role soon.)
\end{enumerate}
\end{problem}

\begin{problem}
\label{pr:fp-iter}

% Let f be a real-valued function.

The "point" of Problem \ref{pr:fp-intro} was preparation for the following general problem: Suppose we have a function $f$, and some value $x_0$ that \textit{isn't} necessarily a fixed point of $f$.

What happens to the sequence $x_0$, $f(x_0)$, $f(f(x_0))$, $f(f(f(x_0)))$, ...? % <don't mention this yet> (Does it converge? Does it oscillate? Does it have some strange chaotic behavior?)

\begin{enumerate}[(a)]
\item Let's first consider $f(x) = x/3$. What does this pattern look like for various starting values?
\item Do the same with 
\begin{enumerate}[i.]
\item $f(x) = \cos(x)$.
\item $f(x) = 2x$. 
\item $f(x) = x/2 + 1$. 
\item $f(x) = 1$ when $x$ is rational, and 0 when $x$ is irrational
\item $f(x) = 4x(1-x)$. % TODO: Reference chaos theory stuff in the references section
\end{enumerate} \hfill

While it is difficult to make general statements on the matter (there are whole fields devoted to the intricacies of this topic!), we can actually prove some pretty cool results.

% TODO: Have "example diagrams" to the right for all of the sub-problems below. (Maybe also in the hints section?)

%(We'll use the $f_k$ notation of Problem \ref{pr:fp-intro} to denote iterated functions.)

\item Suppose $f$ is a \emph{continuous} function, and we \emph{know} that, for some starting value $x_0$, the sequence $x_0$, $f(x_0)$, $f(f(x_0))$, $f(f(f(x_0)))$, ... converges to some value (call it $c$). Prove that $c$ is a fixed point of $f$.

\vspace{10mm}
In other words, if we find that this sequence converges, it converges to a fixed point. But when does it converge in the first place? 

While we won't cover every scenario here, we'll show one interesting case where convergence happens!

% TODO: More parts to this problem that aren't amoeba-related

\item Suppose now that $f$ is a continuous and \emph{increasing} function. Suppose we also choose our "starting point" $x_0$ such that 

\vspace{10mm}
\begin{enumerate}[(1)]
\item $f(x_0) > x_0$, and
\item There is at least one fixed point to the right of $x_0$.
\end{enumerate}

Prove that the sequence $x_0$, $f(x_0)$, $f(f(x_0))$, $f(f(f(x_0)))$, ... converges to the closest such fixed point.
% TODO: Insert logical conclusions for f(x_0) < x_0, f is decreasing, etc? (maybe - don't really need them for amoeba problem)

% TODO: Put diagram for this here or in hints?

% TODO: Also put diagram of what happens for multiple fixed points?

\item Suppose we have the same situation as previously, but our "starting point" $x_0$ is now such that $f(x_0) < x_0$, and we have at least one fixed point to the \emph{left} of $x_0$. Given your above proof, how would we now prove that we converge to the closest fixed point to the left? (Short answer here.)

% TODO: Analogous diagram as above?



\end{enumerate}
\end{problem}


%%%%%%%% Amoeba problems

\begin{problem}
\label{pr:amoeba-ngen}
Suppose we have an amoeba. It has a probability $p_d$ of dying, and a probability $(1 - p_d)$ of dividing into two amoebas (which themselves have the same probabilities of dying vs. dividing). 

We'll say that the first amoeba is the 0th generation. Then, for any $n$-th generation amoeba, if it divides into children, said offspring are $(n+1)$-th generation amoebas. 

Let $P_d(n)$ be the probability that the family tree dies before the $n$-th generation.\footnote{In other words, the probability that this family tree does not produce an $n$-th generation amoeba.}

% TODO: Show tree figures of what this could look like?

\begin{enumerate}[(a)]
\item What is $P_d(1)$?
\item Find a recursive relation for $P_d(n)$, in terms of $P_d(n-1)$, for $n > 1$. 
\item Suppose we instead had $m$ starting amoebas. What is the probability of dying before the $n$-th generation now? Answer in terms of our original $P_d(n)$.
\item What is the probability that our amoeba family (with one starting amoeba) dies at some point in the future, period? (Alternatively, what is the probably that our family \emph{doesn't} die out at all -- and simply lives on forever?) %In particular, under what conditions (i.e. for what values of $p$) is the amoeba family certain to die at some point?
\end{enumerate}
\hfill
\end{problem}

%"Forever" essentially translates to $\lim_{n \rightarrow \infty} P_d(n)$. 

\begin{problem}
\label{pr:amoeba-kdesc}
Suppose we have the situation described in Problem \ref{pr:amoeba-ngen}, but we now have a "magical amoeba" that divides into $k$ children (and so does its descendants, and the descendants after that, etc), where $k \geq 2$. 

% TODO: Recommend (somewhere) to solve (and consult our solution) on ngen problem before this one?
\begin{enumerate}[(a)]
\item Intuitively, what should happen to the probability of the family tree's survival (for any $n$ generations and for eternity), as $k$ increases?
\item For what values of $p_d$ is our "magical amoeba family" certain to die?
\end{enumerate}
\end{problem}

% TODO: This problem will (likely) ultimately lead to Picard iteration
\begin{problem}
\qquad
\begin{enumerate}[(a)]
\item Suppose we have a differentiable function $f: \mathbb{R} \rightarrow \mathbb{R}$, where $0 < f'(x) < 1$ for all $x \in \mathbb{R}$. Prove that there is exactly one fixed point $c$ of $f$, and the sequence $\{f_k(x_0)\}$ (i.e. repeated function iteration) converges to $c$ from any starting point $x_0$ in $\mathbb{R}$. 
% TODO: Hint: Use Problem 2

% TODO: Actually break down the Picard iteration proof into multiple steps
\end{enumerate}
\end{problem}

%%%%%%%%%%%%%%

\newpage
\section{Terms and References}

\section{Hints}

\newpage
\section{Solutions}

\subsection{Problem \ref{pr:fp-iter}}

\subsubsection{Part (c)}

For notation purposes, let's define the sequence $x_n = f_n(x_0)$ (and $x_0$ will just be the initial value from the problem).

We're given that:

\begin{equation*}
\lim_{n \rightarrow \infty} x_n = c
\end{equation*}

In addition,

\begin{align*}
\lim_{n \rightarrow \infty} x_n &= \lim_{n \rightarrow \infty} f(x_{n-1}) \\
&= f(\lim_{n \rightarrow \infty} x_{n-1}) && \text{(Since $f$ is continuous)} \\
&= f(c) \\
\end{align*}

% TODO: Probably have to prove continuity and moving limit through sequence (and then ref it here).
% TODO: Probably have to justify the n-1 (probably show invariance under this in an earlier problem, for general limits)

Therefore, $f(c) = c$, i.e. $c$ is a fixed point of $f$. $\square$

\subsubsection{Part (d)}

Let's use the same $x_n$ notation as we did in Part (c). 


% TODO: Need to have explained this set notation beforehand
% TODO: Will need to have covered least upper bounds and greatest lower bounds,
%	including touching on how they only apply to nonempty sets

Let's also formulate what we mean by converging to the "closest fixed point" more precisely. Suppose we have a set of fixed points $\{c : f(c) = c\}$ which is non-empty, and therefore has a greatest lower bound $c_0$. 

From Problem \ref{continuous-fn-dense-set}, we know that, since $f$ is continuous, $c_0$ is in this set, and hence is a fixed point by definition.\footnote{This is important -- if we didn't establish this fact, then it's not clear that $c_0$ is a fixed point at all, and hence we wouldn't be proving our claim!} We wish to prove that the sequence $\{x_n\}$ converges to $c_0$.

We'll first prove a few preliminaries:

% TODO: Put some figure/illustration for this lemma. 
\begin{lemma}
\label{l:fp-iter-region}
$f(x) > x$ over the region $\left[x_0, c_0\right)$. 
\end{lemma}
\begin{proof}
Let $g(x) = f(x) - x$. Our claim is equivalent to asserting that, over this region, $g(x) > 0$.

We'll do a proof by contradiction. Suppose this weren't true, i.e. there existed at least one point $x_a$ in the region such that $f(x_a) < x_a$, i.e. $g(x_a) < 0$. We're given (in the problem) that $f(x_0) > x_0$, i.e. $g(x_0) > 0$. Therefore, by the intermediate value theorem, there exists a point $x_b$ in $(x_0, x_a)$ such that $g(x_b) = 0$, i.e. $f(x_b) = x_b$. 

Then $x_b$ would be a fixed point. However, we're given that our leftmost fixed point to the right of $x_0$ is $c_0$, and here, $x_0 < x_b < c_0$. Contradiction.
\end{proof}

% TODO: Insert a figure representation of this proof?

% TODO: This won't be our first proof by contradiction (at the very least, it will be that sqrt(2) is irrational), but we do need to account for explaining it (and possibly reviewing it in this problem). 

% TODO: Put two illustrations for this lemma. (One with expected behavior, and one where the assumption isn't followed - and we "overshoot" across the fixed point.)
\begin{lemma}
\label{l:fp-iter-bound}
$\{x_n\}$ is strictly bounded above by $c_0$.
\end{lemma}
\begin{proof}
We'll prove (using induction) that $x_k < c_0$ for all $k \geq 0$. 

Our base case is easy: we're simply given that $x_0 < c_0$.

For the inductive step, we assume that $x_k < c_0$, and show that $x_{k+1} < c_0$. This is short as well -- since $f$ is increasing and $x_k < c_0$, we have $f(x_k) < f(c_0)$. By definition, $x_{k+1} = f(x_k)$, and since $c_0$ is a fixed point, $f(c_0) = c_0$. Therefore, $x_{k+1} < c_0$. 
\end{proof}

% {l:fp-iter-prob-region}

\begin{lemma}
\label{l:fp-iter-increasing-lower-bound}
$\{x_n\}$ is increasing, and bounded below by $x_0$. 
\end{lemma}
\begin{proof}
We'll prove (using induction) that for all $k \geq 0$, $x_0 \leq x_k < x_{k+1}$ (i.e. both $x_0 \leq x_k$, and $x_k < x_{k+1}$). 

For our base case, clearly $x_0 \leq x_0$. We are given that $f(x_0) > x_0$, and by definition of our sequence, $x_1 = f(x_0)$, so $x_0 < x_1$.

For our inductive step, we assume $x_0 \leq x_k < x_{k+1}$, and prove that $x_0 \leq x_{k+1} < x_{k+2}$. Since $x_0 \leq x_k < x_{k+1}$, we clearly have $x_0 \leq x_{k+1}$. Per Lemma \ref{l:fp-iter-bound}, we have $x_{k+1} < c_0$. Therefore, we have that $x_{k+1} \in \left[x_0, c_0\right)$, so by Lemma \ref{l:fp-iter-region}, $f(x_{k+1}) > x_{k+1}$. By definition, $x_{k+2} = f(x_{k+1})$, so $x_{k+1} < x_{k+2}$. 

% TODO: Mention something like (We proved the increasing and lower boundedness statement together because they are intricately linked in our proof.)
\end{proof}

From Lemmas \ref{l:fp-iter-bound} and \ref{l:fp-iter-increasing-lower-bound}, we see that $\{x_n\}$ is an increasing and bounded sequence. Therefore, by Theorem \ref{th:monotone-seq}, $\{x_n\}$ converges (to its least upper bound, specifically). Therefore, by Part (c), it must converge to a fixed point.

We finally show that, therefore, $\{x_n\}$ must converge to $c_0$. As for the fixed points greater than $c_0$, clearly none of them can be a least upper bound by definition, so convergence to them is out of the question.

What about the fixed points to the \emph{left} of $x_0$? (We haven't discussed these at all yet!) From Lemma \ref{l:fp-iter-increasing-lower-bound}, $x_0$ is a lower bound for our sequence. Since $x_0$ isn't a fixed point itself (since $f(x_0) > x_0$), any such fixed points must be strictly less than $x_0$. Therefore (even ignoring the fact that $\{x_n\}$ is increasing and could never approach such a fixed point), the bound means that we would not be able to get with arbitrary $\epsilon$ distance of a fixed point to the left.

This all leaves us with only one possibility: $\{x_n\}$ converges to $c_0$, the smallest fixed point to the right of our starting point $x_0$.

% TODO: We need to introduce the $\{x_n\}$ notation at some point.

% TODO: Go back to the problem and revise problem statement (or at least add caveat that we could have a solid real-line block of real numbers where f(x) = x, and hence we can't index them. In this case there would be an *uncountable* number of fixed points (we may or may not have already talked about countability at that point?)
% 	- Possible way to revise the problem: There is at least one fixed point to the right of $x_0$. Let $c_0$ be the lowest such fixed point. Prove that sequence must converge to $c_0$.

% TODO: Might want to just say "greater than", rather than "to the right of"
 



\subsection{Problem \ref{pr:amoeba-ngen}}

\subsubsection{Part (a)}

$P_d(1)$ is simply the probability that we don't make it to first generation. This will only happen if the first amoeba dies, which happens with probability $p_d$.



\subsubsection{Part (b)}

A recap of the scenario here: We have one amoeba, and we'd like to see whether (or not) it produces a family tree that lives to at least $n$ generations.

% TODO: Potentially bee more clear here. Emphasize using the "divide the world into two possibilities" trick
There are two (mutually exclusive) ways for that amoeba's family tree to die off before then: 
\begin{enumerate}
\item This amoeba dies.
\item This amoeba lives to divide into two, but the family dies off later on.
\end{enumerate} \hfill

Let's clarify the second case a bit more. If our current amoeba has lived to reproduce, then the only way for the family to die out before $n$ generations is if \emph{both} of our children amoebas produce families that die out before $(n-1)$ generations, respective to them. By our definition, each such child amoeba has probability $P_d(n-1)$ of that occurring.

This looks promising recurrence-relation wise! Let's solidify our relation a bit more formally. We have: \footnote{It might seem a bit silly to write "dies in $<n$ generations from parent death" -- after all, not only does it die before the $n$-th generation, it dies before even the first one! But bear with us here.}

\begin{align*}
P_d(n) &:= P(\text{ family dies in $< n$ generations }) \\
&= P(\text{ family dies in $< n$ generations from parent death }) \\
&\qquad + P(\text{ family dies in $< n$ generations from later death }) \\ % mutually exclusive
\end{align*}


Rephrasing this a little bit, we have: \footnote{Note that, in the second equation, we're using the general notion that $P(B \cap A) = P\left(B \middle| A\right) \cdot P(A)$}
\begin{align*}
&= P(\text{ family dies in $< n$ generations AND parent dies }) \\
&\qquad + P(\text{ family dies $< n$ generations AND parent lives }) \\
&= P(\text{ parent dies }) \cdot P\left(\text{ family dies } \middle| \text{ parent dies }\right) \\
&\qquad + P(\text{ parent lives }) \cdot P\left(\text{ family dies } \middle| \text{ parent lives }\right) \\
&= p_d \cdot 1 \\
&\qquad + (1 - p_d) \cdot P\left(\text{ family dies } \middle| \text{ parent lives }\right)
\end{align*}

What is $P\left(\text{ family dies } \middle| \text{ parent lives }\right)$? In other words, what exactly is the probability that, even though the first amoeba divides into two, our family dies in $n$ generations (relative to the first amoeba) anyway? We know that each child amoeba then has to die in less than $(n-1)$ generations, which happens with probability $P_d(n-1)$, and there are two children. The reproduction of each child is independent of the other child, and hence both amoebas must independently have their family lines die under them in order for the amoeba line as a whole to die.

Therefore, 

\begin{align*}
&P\left(\text{ family dies in $<n$ generations } \middle| \text{ parent lives }\right) \\
&= P(\text{ family dies under child 1} \\
&\qquad\text{ AND family dies under child 2 }) \\
&= P\left(\text{ family dies under child 1} \right) \\ 
&\qquad\cdot P\left(\text{ family dies under child 2 } \right) \\
&= P_d(n-1) \cdot P_d(n-1) \\
&= P_d(n-1)^2
\end{align*}

%TODO: Fix super/subscript formatting
%TODO: "Generations" term is wrong, use some other word (like line)

Combining everything above, we get that $p_F$ must satisfy the following relation:

\begin{equation}
P_d(n) = p_d + (1-p_d) \cdot P_d(n-1)^2
\end{equation}


\subsubsection{Part (c)}

If we have $m$ starting amoebas, each amoeba proceeds in producing its family tree independently. In order for us to have no amoebas at generation $n$, each amoeba's family tree must independently die out before them. Hence, using very similar logic as in Part (b)'s independence discussion, we simply multiply for each of the $m$ amoebas, giving us $P_d(n)^m$. 

As a quick check on ourselves: Since probabilities are between 0 and 1, inclusive, $P_d(n)^m$ will decrease as $m$ increases. This is exactly what we expect, since our chances of complete death should go much lower if we have more amoebas to start with.

% TODO: Actually do the work here? 

\subsubsection{Part (d)}

We'd like to find the chances that our amoeba family simply never dies, and simply keeps on living forever. Alternatively, we're trying to find the probability that this \emph{doesn't} happen -- in other words, the probability that, at some point, the family dies.\footnote{The probability of either possibility is, of course, 1 minus the other.}

In theory, the latter possibility is simply the limit of $P_d(n)$ as $n$ approaches infinity. 

What is this limit? Does it even exist? Trying to find an explicit formula for $P_d(n)$ from our recurrence relation looks messy, at best (but you can try!) -- so let's try a different look at the problem.


\paragraph{Brief intuition}

Let's first try to intuit what happens -- in particular, at a few "edge" cases.

First, let's consider what happens at $p_d = 0$, which means that every amoeba will reproduce without dying. Then our family should obviously live forever, so our family death probability (for any $n$, and the limit as $n$ approaches infinity) should be 0.\footnote{Going back to our recurrence relation, this makes sense -- when $p_d = 0$, we have $P_d(n) = 0 + (1 - 0) \cdot P_d(n-1) = P_d(n-1)$. Given that $P_d(1) = p_d = 0$, it follows that $P_d(n) = 0$ for all $n$.}

Let's also consider what happens when $p_d > 1/2$. This effectively means that it is more likely for an amoeba to die than it is to reproduce. If we look at this from an "expected value" viewpoint, then we expect the population to go down as time goes on -- so our survival probability in the timeframe of "forever" should be very low, if anything at all!

But let's do a more rigorous analysis. Will it support our intuition?


\paragraph{Fixed-point iteration returns!}

Consider the function $f(x) = p_d + (1 - p_d)x^2$. 

Let's say we have $x_0 = P_d(1) = p_d$, from Part (a). Then, by definition, $P_d(2)$ is equal to $f(x_0)$. Furthermore, $P_d(3) = f(P_d(2)) = f(f(x_0))$, and $P_d(4) = f(P_d(3)) = f(f(f(x_0)))$, and so on.

This is starting to look like a function iteration problem! More specifically, we can say $P_d(n+1) = f_n(x_0)$ for $n > 1$. 

From our previous problems, we have a hunch that the fixed points of $f$ can be important. They are simply the solutions to the equation $x = f(x)$, i.e.

\begin{equation*}
x = p_d + (1 - p_d)x^2
\end{equation*}

Solving this equation\footnote{We can use the "quadratic formula" here.} gives two solutions (which we'll call $x_a$ and $x_b$):
\begin{equation*}
x_a = 1
\end{equation*}
and 
\begin{equation*}
x_b = \frac{p_d}{1 - p_d}
\end{equation*}

One key thing we see: $x_a = x_b$ when $p_d = 1/2$. In fact, when $p_d > 1/2$, $x_b > x_a$ (and when $p_d < 1/2$, $x_b < x_a$). 

% TODO: Insert figure of graph for various values of p_d. Give one color to those < 1/2, one to those >, and one to those equal. Put dots at the fixed points



\paragraph{The actual solution}

Why was that all important? Three more key facts:

\begin{itemize}
\item $f$ is continuous and increasing for $x > 0$. 
\item $f(x) > x$ before the first fixed point. 
\item Our starting point, $x_0$, is simply $p_d$. Note that $p_d \leq x_a$ (because $p_d \leq 1$), and since $(1 - p_d) \leq 1$, we have $p_d \leq x_b$ as well. Hence, our starting point is to the left of both fixed points (or on top of one -- we'll take care of that special case shortly). 
\end{itemize}

Now comes our big realization. Remember Problem \ref{pr:fp-iter}? We've met all the conditions to show that, once we start iterating at $p_d$, our limit is the \emph{closest} fixed point to the right -- in other words, the lesser of $x_a$ and $x_b$.

What does that mean for us? Let's consider 3 cases:

\begin{itemize}
\item $p_d > 1/2$: The leftmost fixed point is 1, so our iterated function limit, i.e. $\lim_{n \rightarrow \infty} P_d(n)$, is 1. Therefore, our amoeba family is certain to die at some point. (How sad.)\footnote{We actually could have had a quick "side-channel" solution for this case. If $p_d > 1/2$, then $p_d / (1 - p_d) > 1$, so it would be nonsensical to have that has a probability value. However, hopefully you'd agree that our more rigorous work-through gives a more solid justification.}
\item $p_d = 1/2$: Here, in fact, we only have one fixed point (since $x_a = x_b$), which is 1. Hence, our amoeba family will, at some point, die.
\item $p_d < 1/2$: The leftmost fixed point is now $p_d / (1 - p_d)$, which must then be our iterated function limit (i.e. $\lim_{n \rightarrow \infty} P_d(n)$). Therefore, with probability $1 - \frac{p_d}{1-p_d}$, our amoeba family lives on forever!
\end{itemize}


\paragraph{(Philosophizing)}

%TODO: More intuition? (especially in the expected-value sense)

% TODO: Get more into what this p_d / (1 - p_d) relation looks like? (Graph, numerical example at edge cases, etc) instead of (just?) the numerical example below.

% TODO: More philosophizing in general

% TODO: Possibly make this whole thing link back to "first principles" (probability spaces, etc). However, this can probably occur in the recurrence relation section. 

$\square$


\subsection{Problem \ref{pr:amoeba-kdesc}}

\subsubsection{Part (a)}

Intuitively (or at the very least, "it feels like") the probability of family death should decrease as $k$ increases.

Consider the following: The "further one gets" along the family tree, the more likely it seems that the family will survive indefinitely. As a brief example, consider having the one starting amoeba versus the two amoebas that come after it in our original (upon successful reproduction) -- our conditional chances are a lot better in the latter case.\footnote{More precisely, as we found earlier, the chances of death are $p_F^2$ after division, as opposed to $p_F$ before it -- and since $0 \leq p_F \leq 1$, $p_F^2 < p_F$.}

As $k$ increases, the degree to which we're "better off" after our first amoeba should be much higher. In fact, the big determiner in our family survival should be whether the first amoeba dies!\footnote{Think "carrying the team" here.} Therefore, intuitively, the probability of family survival should approach the probability of the first amoeba's death, which is simply $p_d$. 

Of course, in the last problem, we ran into the issue where, if $p_d$ is too high, family death is simply certain. When is $p_d$ too high here? We'll find out in the next part!

\subsubsection{Part (b)}

To start, we'll take a very similar approach as that of the last problem.

\paragraph{Preliminary work}

We'll re-use notation a bit, and let $P_d(n)$ denote the probability of family death before $n$ generations. 

Hopefully you believe that, with $k$ descendants per (surviving) amoeba, 

\begin{equation*}
P_d(n) = p_d + (1 - p_d) P_d(n-1)^k
\end{equation*}

Now, consider the function 

\begin{equation}
f(x) = p_d + (1 - p_d) x^k
\end{equation} 

Using the same logic as before, we now have $P_d(n+1) = f_n(p_d)$.\footnote{Inserting our starting value here directly, instead of calling it $x_0$.}

\paragraph{(Exploration)}

We now have a slight problem: For arbitrary $k$, we can't explicitly solve for all of the fixed points of $f$. % TODO: Mention why - might be able to link back into previous work

Let's explore a bit. What happens if we keep $p$ constant, and vary $k$?

% TODO: Insert "thinking" and graphs of what happens as we vary k, and as we vary p

What happens if we keep $k$ constant, and vary $p$?

% TODO: Philosophize more on exploration

% TODO stuff to write: It seems like we still have a very similar to the $k = 2$ case - it's almost as if we still have two fixed points, except perhaps at some "turning point". It also seems like x = 1 is still always a fixed point, and that the other one "moves to the right" as p_d increases, until it passes 1. The probability at which it passes 1 seems to be a higher value of p, as k increases.
%
% In addition, we see the behavior we intuitively thought about earlier -- as k increases (with p_d held constant), it looks like, as long as p_d is low enough, the leftmost fixed point approaches p_d


\paragraph{The actual proof}

%We'll now prove that $f$ has at most two fixed points. In the process, we'll show what $p_d$ has to be, in order for death to be certain! 

Consider the function

\begin{align*}
g(x) &= f(x) - x \\
&= p_d + (1 - p_d)x^k - x
\end{align*}

Note that the fixed points will occur whenever $g(x) = 0$.\footnote{Since then $f(x) - x = 0$, i.e. $f(x) = x$}

Then

\begin{equation}
g'(x) = (1 - p_d)kx^{k-1} - 1
\end{equation}

and

\begin{equation}
g''(x) = (1 - p_d)k(k-1)x^{k-2}
\end{equation}

Note that $g''(x)$ is positive whenever $x > 0$, so from $x = 0$ on, $g$ is convex. Per Problem \ref{pr:convex-root-limit}, we know that $g$ will have at most 2 roots. In the course of that proof, we also saw that, if $g$ has two distinct roots $x_a$ and $x_b$, where $x_a < x_b$, then $g'(x_a) < 0$, and $g'(x_b) > 0$ -- and if $g$ has only one distinct root $x_a$, then $g'(x_a) = 0$. % TODO: Mention something like "recall that it could have 0, 1, or 2, depending on (cases)"

We clearly see (by plugging in) that $g(1) = 0$, which gives us at least one root.\footnote{This makes sense: From our graphs, we suspected that this was true. One could have also plugged in to see that $f(1) = p_d + (1 - p_d) = 1$.}

This leaves us three possibilities:

\begin{itemize}
\item $g$ has an additional root $x_a < 1$: Then $g'(x_a) < 0$, and $g'(1) > 0$.
\item $g$ has an additional root $x_a > 1$: Then $g'(x_a) > 0$, and $g'(1) < 0$.
\item $g$ has exactly one root, at $x = 1$: Then $g'(1) = 0$.
\end{itemize}

% TODO: Figure describing these three possibilities. Label things!

Combining these three statements, we now have an "if and only if" relationship between these three cases and the value of $g'(1)$. 

What is it? Plugging in, we see that $g'(1) = (1 - p_d)k - 1$. Solving, we then see that $g'(1) = 0$ when $p_d = (k-1)/k$. Moreover, when $p_d < (k-1)/k$, $g'(1) > 0$ (and conversely, when $p_d > (k-1)/k$, $g'(1) < 0$). 

\paragraph{More proof}

What does this mean in terms of our fixed-point iteration and final answer?

In preparation, we point out three final facts: First, $f$ itself is increasing. Second, at our iteration starting point, $p_d$, we note that $g(p_d) = p_d + (1 - p_d)p_d^k - p_d = (1 - p_d)p_d^k \geq 0$ (and is, in fact, greater than 0 unless $p_d = 1$). Therefore, $p_d$ must be either in the "first" (before both roots) or "second" (after both roots) region where $g$ is positive. However, since $p_d \leq 1$, it cannot be in the second region, and hence must come before both roots. This has the consequence that, if there is a second distinct root $x_a$ of $g$, it must satisfy $x_a > p_d$. 

% TODO: Go back and clarify the \leqs vs less-thans - in other words, the edge cases in general.

Finally, as in the previous problem, we satisfy the conditions to use the result of Problem \ref{pr:fp-iter} -- and hence, we know that our iteration will converge to the nearest fixed point to the right of $p_d$, our initial starting point.

Let's now revisit our cases above. 

\begin{itemize}
\item When $p_d > (k-1)/k$, then $g'(1) < 0$, so there is a second root $x_a$ of $g$ (i.e. a second fixed point of $f$), where $x_a > 1$. Hence, 1 is the closest root, and hence our iteration converges there. Therefore, $\lim_{n \rightarrow \infty} P_d(n) = 1$, and hence our amoeba family will die. 
\item When $p_d = (k-1)/k$, then $g'(1) = 0$, so we have only the root $x = 1$ (and hence only that fixed point of $f$). Therefore, our iteration converges to it, hence $\lim_{n \rightarrow \infty} P_d(n) = 1$, and the family dies.
\item However, when $p_d < (k-1)/k$, $g'(1) > 0$, so we have one root of $g$ (read: fixed point of $f$) $x_a$ which is less than 1. From above, we know that $x_a > p_d$, so it is the nearest rightmost fixed point of $p_d$. Hence, our iteration converges to a value less than 1, so our amoeba family has hope for eternal survival. 
\end{itemize}

% TODO: Philosophize. Kind of amazing how we could conclude this without actually knowing what the root even is. 
% 
% Also what did we do here? In theory, we could have done this when k = 2, in the last problem. However, we had the solutions explicitly there. Here, we had to show that an additional solution besides x = 1 exists, even though we can't actually give a formula for it. 






